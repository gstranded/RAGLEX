from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
import uvicorn
import httpx
import re
import sqlite3
from datetime import datetime
import uuid
import os
from pathlib import Path
import aiofiles
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from chain import get_law_chain_intent, get_law_chain
from config import config
from callback import OutCallbackHandler
from schemas import KnowledgeUploadData, CaseStructure, IdealCaseStructure
import permission_manager
from permission_manager import get_user_private_files, get_public_files
from utils import (
    get_vectorstore, get_model_openai, get_memory, 
    rerank_documents_doc, get_embeder,
    get_law_vectorstore, get_case_vectorstore,
    search_law_documents, search_case_documents,
    search_case_documents_with_user_filter,
    rerank_existing_documents, get_model,
    add_single_file_to_vectorstore
)
from prompt import (
    PRE_QUESTION_PROMPT, CHECK_INTENT_PROMPT, 
    LAW_PROMPT_HISTORY, FRIENDLY_REJECTION_PROMPT,
    MULTI_QUERY_PROMPT_TEMPLATE
)
# ç½‘ç»œæœç´¢åŠŸèƒ½å®ç°
def search_web_serper(query: str, num_results: int = 3) -> str:
    """
    ä½¿ç”¨Serper APIè¿›è¡Œç½‘ç»œæœç´¢
    
    Args:
        query: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
        num_results: è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤ä¸º3
        
    Returns:
        æ ¼å¼åŒ–çš„æœç´¢ç»“æœå­—ç¬¦ä¸²
    """
    import requests
    import json
    
    try:
        # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
        serper_api_key = os.getenv('SERPER_API_KEY')
        if not serper_api_key:
            print("è­¦å‘Š: æœªæ‰¾åˆ°SERPER_API_KEYç¯å¢ƒå˜é‡")
            return "ç½‘ç»œæœç´¢ä¸å¯ç”¨ï¼šç¼ºå°‘APIå¯†é’¥"
        
        # Serper APIé…ç½®
        url = "https://google.serper.dev/search"
        headers = {
            'X-API-KEY': serper_api_key,
            'Content-Type': 'application/json'
        }
        
        # è¯·æ±‚æ•°æ®
        payload = {
            "q": query,
            "num": num_results,
            "hl": "zh-cn",  # ä¸­æ–‡æœç´¢
            "gl": "cn"      # ä¸­å›½åœ°åŒº
        }
        
        # å‘é€è¯·æ±‚
        response = requests.post(url, headers=headers, json=payload, timeout=10)
        response.raise_for_status()
        
        data = response.json()
        
        # è§£ææœç´¢ç»“æœ
        results = []
        if 'organic' in data:
            for item in data['organic'][:num_results]:
                title = item.get('title', 'æ— æ ‡é¢˜')
                snippet = item.get('snippet', 'æ— æ‘˜è¦')
                link = item.get('link', 'æ— é“¾æ¥')
                
                # æ ¼å¼åŒ–å•ä¸ªç»“æœ
                formatted_result = f"æ ‡é¢˜: {title}\næ‘˜è¦: {snippet}\næ¥æº: {link}"
                results.append(formatted_result)
        
        if results:
            # ç”¨åŒæ¢è¡Œç¬¦è¿æ¥å¤šä¸ªç»“æœ
            return "\n\n".join(results)
        else:
            return "æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœ"
            
    except requests.exceptions.RequestException as e:
        print(f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {e}")
        return "ç½‘ç»œæœç´¢å¤±è´¥ï¼šè¯·æ±‚é”™è¯¯"
    except json.JSONDecodeError as e:
        print(f"JSONè§£æé”™è¯¯: {e}")
        return "ç½‘ç»œæœç´¢å¤±è´¥ï¼šå“åº”è§£æé”™è¯¯"
    except Exception as e:
        print(f"æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return "ç½‘ç»œæœç´¢å¤±è´¥ï¼šæœªçŸ¥é”™è¯¯"
from langchain.schema.output_parser import StrOutputParser
from langchain_core.documents import Document
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import MarkdownTextSplitter
from langchain.output_parsers import PydanticOutputParser
from langchain_core.prompts import PromptTemplate
from rank_bm25 import BM25Okapi
from dotenv import load_dotenv
from pathlib import Path
import logging
import numpy as np
import aiohttp
import aiofiles
import os

app = FastAPI(title="çŸ¥è¯†åº“ä¸Šä¼ æ¥æ”¶æœåŠ¡")

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

logger = logging.getLogger(__name__)

# æ•°æ®æ¨¡å‹å®šä¹‰
# æ•°æ®åº“åˆå§‹åŒ–
def init_database():
    """ã€æ–°æ¶æ„ç‰ˆã€‘åˆå§‹åŒ–SQLiteæ•°æ®åº“ï¼Œåˆ›å»ºfileså’Œfile_permissionsè¡¨"""
    conn = sqlite3.connect('knowledge_files.db')
    cursor = conn.cursor()
    
    # å¼€å¯å¤–é”®çº¦æŸï¼Œè¿™å¯¹äºON DELETE CASCADEè‡³å…³é‡è¦
    cursor.execute("PRAGMA foreign_keys = ON;")

    # 1. åˆ›å»ºæ–°çš„ files è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS files (
            file_id INTEGER PRIMARY KEY,
            user_id INTEGER NOT NULL,
            title TEXT NOT NULL,
            file_path TEXT NOT NULL UNIQUE,
            file_category TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # 2. åˆ›å»ºæ–°çš„ file_permissions è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS file_permissions (
            permission_id INTEGER PRIMARY KEY AUTOINCREMENT,
            file_id INTEGER NOT NULL,
            permission_type TEXT NOT NULL, -- 'public' æˆ– 'private'
            owner_id INTEGER,              -- ç±»å‹ä¸º 'private' æ—¶ï¼Œæ­¤å¤„ä¸º user_id
            FOREIGN KEY (file_id) REFERENCES files (file_id) ON DELETE CASCADE
        )
    ''')
    
    conn.commit()
    conn.close()
    print("[DB_INIT] æ–°æ¶æ„æ•°æ®åº“è¡¨åˆå§‹åŒ–/æ£€æŸ¥å®Œæˆã€‚")

# add_file_and_permissionså‡½æ•°å·²ç§»åŠ¨åˆ°permission_manager.pyæ¨¡å—ä¸­

# å·²åˆ é™¤ get_file_path_by_id - åŸºäºæ—§è¡¨ç»“æ„ï¼Œå·²è¢«æ–°æ¶æ„å–ä»£

# å·²åˆ é™¤ delete_file_record - åŸºäºæ—§è¡¨ç»“æ„ï¼Œå·²è¢«æ–°æ¶æ„å–ä»£

def sanitize_filename(name: str) -> str:
    """æ–‡ä»¶åå®‰å…¨å‡€åŒ–"""
    if not name or name.strip() == "":
        return "æ— æ ‡é¢˜æ–‡æ¡£"
    
    # ç§»é™¤æˆ–æ›¿æ¢éæ³•å­—ç¬¦
    sanitized = re.sub(r'[/\\:*?"<>|]', '_', name)
    # æ›¿æ¢è¿ç»­ç©ºæ ¼ä¸ºå•ä¸ªç©ºæ ¼
    sanitized = re.sub(r'\s+', ' ', sanitized)
    # ç§»é™¤é¦–å°¾ç©ºæ ¼å’Œç‚¹
    sanitized = sanitized.strip(' .')
    # é™åˆ¶é•¿åº¦
    if len(sanitized) > 100:
        sanitized = sanitized[:100]
    
    return sanitized if sanitized else "æ— æ ‡é¢˜æ–‡æ¡£"

def format_data_to_markdown(data: dict) -> str:
    """å°†ç»“æ„åŒ–æ•°æ®æ ¼å¼åŒ–ä¸ºMarkdown"""
    markdown_content = f"""# {data.get('æ ‡é¢˜', 'æ— æ ‡é¢˜')}

## åŸºæœ¬ä¿¡æ¯

**æ¡ˆä¾‹ç±»å‹**: {data.get('æ¡ˆä¾‹ç±»å‹', 'æœªçŸ¥')}

**å…³é”®è¯**: {', '.join(data.get('å…³é”®è¯', []))}

**å½“äº‹äºº**: {', '.join(data.get('å½“äº‹äºº', []))}

## äº‰è®®ç„¦ç‚¹

{data.get('äº‰è®®ç„¦ç‚¹', 'æ— ')}

## æ³•å¾‹æ¡æ–‡

{chr(10).join([f'- {item}' for item in data.get('æ³•å¾‹æ¡æ–‡', [])])}

## åˆ¤å†³ç»“æœ

{data.get('åˆ¤å†³ç»“æœ', 'æ— ')}

## æ¡ˆä¾‹è¦ç‚¹

{data.get('æ¡ˆä¾‹è¦ç‚¹', 'æ— ')}

## é€‚ç”¨æ³•æ¡

{chr(10).join([f'- {item}' for item in data.get('é€‚ç”¨æ³•æ¡', [])])}

## æ¡ˆä¾‹æ„ä¹‰

{data.get('æ¡ˆä¾‹æ„ä¹‰', 'æ— ')}
"""
    return markdown_content

def extract_text_from_file(file_path: str) -> str:
    """ä»æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹"""
    try:
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext == '.pdf':
            try:
                import pypdf
                with open(file_path, 'rb') as file:
                    reader = pypdf.PdfReader(file)
                    text = ""
                    for page in reader.pages:
                        text += page.extract_text() + "\n"
                    return text
            except ImportError:
                logger.error("pypdfåº“æœªå®‰è£…ï¼Œæ— æ³•å¤„ç†PDFæ–‡ä»¶")
                return ""
        
        elif file_ext == '.docx':
            try:
                import docx
                doc = docx.Document(file_path)
                text = ""
                for paragraph in doc.paragraphs:
                    text += paragraph.text + "\n"
                return text
            except ImportError:
                logger.error("python-docxåº“æœªå®‰è£…ï¼Œæ— æ³•å¤„ç†DOCXæ–‡ä»¶")
                return ""
        
        elif file_ext in ['.txt', '.md']:
            with open(file_path, 'r', encoding='utf-8') as file:
                return file.read()
        
        else:
            logger.warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
            return ""
            
    except Exception as e:
        logger.error(f"æ–‡æœ¬æå–å¤±è´¥: {str(e)}")
        return ""

def clean_llm_json_output(raw_output: str) -> str:
    """æ¸…ç†LLMè¾“å‡ºä¸­çš„æ ¼å¼é—®é¢˜"""
    import re
    import json
    
    # ç§»é™¤```jsonæ ‡è®°
    cleaned = re.sub(r'```json\s*', '', raw_output)
    cleaned = re.sub(r'```\s*$', '', cleaned)
    
    # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„å¤šä½™ç©ºç™½
    cleaned = cleaned.strip()
    
    # å°è¯•æ‰¾åˆ°JSONå¯¹è±¡çš„å¼€å§‹å’Œç»“æŸ
    start_idx = cleaned.find('{')
    end_idx = cleaned.rfind('}')
    
    if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
        json_str = cleaned[start_idx:end_idx+1]
        
        # å¤„ç†é‡å¤å­—æ®µé—®é¢˜
        try:
            # å…ˆå°è¯•ç›´æ¥è§£æ
            json.loads(json_str)
            return json_str
        except json.JSONDecodeError:
            # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä¿®å¤é‡å¤å­—æ®µ
            lines = json_str.split('\n')
            seen_keys = set()
            cleaned_lines = []
            
            for line in lines:
                # æ£€æŸ¥æ˜¯å¦æ˜¯é”®å€¼å¯¹è¡Œ
                if ':' in line and '"' in line:
                    # æå–é”®å
                    key_match = re.search(r'"([^"]+)"\s*:', line)
                    if key_match:
                        key = key_match.group(1)
                        if key in seen_keys:
                            continue  # è·³è¿‡é‡å¤çš„é”®
                        seen_keys.add(key)
                
                cleaned_lines.append(line)
            
            return '\n'.join(cleaned_lines)
    
    return cleaned

def structure_content_with_llm(raw_text: str) -> dict:
    """ã€å…¨æ–°å‡çº§ç‰ˆã€‘ä½¿ç”¨LLMå¯¹å†…å®¹è¿›è¡Œæ·±åº¦åŠ å·¥å’Œç»“æ„åŒ–å¤„ç†"""
    try:
        # æ³¨æ„ï¼šè¿™é‡Œçš„parserç°åœ¨ä½¿ç”¨æ–°çš„IdealCaseStructure
        parser = PydanticOutputParser(pydantic_object=IdealCaseStructure)
        
        # ä½¿ç”¨æ–°çš„ã€æ›´å¼ºå¤§çš„Prompt
        from prompt import TRANSFORM_AND_STRUCTURE_PROMPT_TEMPLATE
        prompt_template = PromptTemplate(
            template=TRANSFORM_AND_STRUCTURE_PROMPT_TEMPLATE,
            input_variables=["text"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        # è·å–æ¨¡å‹
        model = get_model_openai()
        
        print("[INFO] å¯åŠ¨LLMè¿›è¡Œæ·±åº¦åŠ å·¥ä¸ç»“æ„åŒ–...")
        
        # åˆ†æ­¥å¤„ç†ï¼šå…ˆè·å–åŸå§‹å“åº”ï¼Œå†æ¸…ç†ï¼Œæœ€åè§£æ
        formatted_prompt = prompt_template.format(text=raw_text[:8000])
        raw_response = model.invoke(formatted_prompt)
        
        print(f"[DEBUG] LLMåŸå§‹å“åº”é•¿åº¦: {len(raw_response.content)}")
        
        # æ¸…ç†å“åº”å†…å®¹
        cleaned_content = clean_llm_json_output(raw_response.content)
        print(f"[DEBUG] æ¸…ç†åå†…å®¹é•¿åº¦: {len(cleaned_content)}")
        
        # ä½¿ç”¨parserè§£ææ¸…ç†åçš„å†…å®¹
        result = parser.parse(cleaned_content)
        
        # ä½¿ç”¨ .model_dump() ä»£æ›¿ .dict()
        return result.model_dump()
            
    except Exception as e:
        logger.error(f"LLMç»“æ„åŒ–å¤„ç†å¤±è´¥: {str(e)}")
        print(f"[ERROR] è¯¦ç»†é”™è¯¯ä¿¡æ¯: {e}")
        
        # å¤±è´¥æ—¶è¿”å›ä¸€ä¸ªç©ºçš„ã€ç¬¦åˆæ–°ç»“æ„çš„å­—å…¸
        return IdealCaseStructure(
            æ ‡é¢˜="æ–‡æ¡£è§£æå¤±è´¥", å…³é”®è¯=[], æ¡ˆä¾‹ç±»å‹="æœªçŸ¥", åŸºæœ¬æ¡ˆæƒ…="è§£æå¤±è´¥",
            è£åˆ¤ç†ç”±="è§£æå¤±è´¥", è£åˆ¤è¦æ—¨="è§£æå¤±è´¥", æ³•å¾‹æ¡æ–‡=[]
        ).model_dump()

def format_ideal_case_to_markdown(data: dict) -> str:
    """å°†æ–°çš„ã€ç†æƒ³æ ¼å¼çš„ç»“æ„åŒ–æ•°æ®æ ¼å¼åŒ–ä¸ºMarkdown"""
    
    # ä½¿ç”¨.get(key, default_value)æ¥å®‰å…¨åœ°è·å–æ•°æ®
    title = data.get('æ ‡é¢˜', 'æ— æ ‡é¢˜')
    keywords = ", ".join(data.get('å…³é”®è¯', []))
    case_type = data.get('æ¡ˆä¾‹ç±»å‹', 'æœªæä¾›')
    case_number = data.get('æ¡ˆä¾‹ç¼–å·', 'æœªæä¾›')
    basic_facts = data.get('åŸºæœ¬æ¡ˆæƒ…', 'æœªæä¾›')
    reasoning = data.get('è£åˆ¤ç†ç”±', 'æœªæä¾›')
    gist = data.get('è£åˆ¤è¦æ—¨', 'æœªæä¾›')
    articles = "\n".join([f"- {item}" for item in data.get('æ³•å¾‹æ¡æ–‡', [])]) if data.get('æ³•å¾‹æ¡æ–‡') else 'æœªæä¾›'
    court = data.get('æ³•é™¢', 'æœªæä¾›')
    judgment_date = data.get('åˆ¤å†³æ—¥æœŸ', 'æœªæä¾›')

    markdown_content = f"""# {title}

## å…³é”®è¯

{keywords}

## æ¡ˆä¾‹ç±»å‹

{case_type}

## æ¡ˆä¾‹ç¼–å·

{case_number}

## åŸºæœ¬æ¡ˆæƒ…

{basic_facts}

## è£åˆ¤ç†ç”±

{reasoning}

## è£åˆ¤è¦æ—¨

{gist}

## æ³•å¾‹æ¡æ–‡

{articles}

## æ³•é™¢

{court}

## åˆ¤å†³æ—¥æœŸ

{judgment_date}
"""
    return markdown_content

# add_single_file_to_vectorstore å‡½æ•°å·²ç§»è‡³ utils.py ä½œä¸ºç»Ÿä¸€çš„å®ˆé—¨å‘˜å‡½æ•°

async def handle_existing_file_update(data: KnowledgeUploadData, existing_file_info: dict, pm):
    """å¤„ç†å·²å­˜åœ¨æ–‡ä»¶çš„æ™ºèƒ½æ›´æ–°æ“ä½œ - è½»é‡çº§æ›´æ–°"""
    try:
        print(f"[DEBUG] æ™ºèƒ½æ›´æ–°: å¼€å§‹å¤„ç†å·²å­˜åœ¨æ–‡ä»¶ {data.file_id}")
        logger.info(f"æ™ºèƒ½æ›´æ–°: å¼€å§‹å¤„ç†å·²å­˜åœ¨æ–‡ä»¶ {data.file_id}")
        
        # è·å–å½“å‰æ–‡ä»¶ä¿¡æ¯
        current_file_path = existing_file_info.get('file_path')
        current_title = existing_file_info.get('title', 'untitled')
        
        print(f"[DEBUG] æ™ºèƒ½æ›´æ–°: å½“å‰æ–‡ä»¶è·¯å¾„: {current_file_path}")
        print(f"[DEBUG] æ™ºèƒ½æ›´æ–°: å½“å‰æ–‡ä»¶æ ‡é¢˜: {current_title}")
        
        # ç¡®å®šæ–°çš„å­˜å‚¨è·¯å¾„å’Œå…ƒæ•°æ®
        knowledge_types = data.knowledge_types if data.knowledge_types else ['private']
        print(f"[DEBUG] æ™ºèƒ½æ›´æ–°: æ–°çš„çŸ¥è¯†åº“ç±»å‹: {knowledge_types}")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ··åˆæ¨¡å¼
        is_hybrid = 'public' in knowledge_types and 'private' in knowledge_types
        
        if is_hybrid:
            new_target_dir = '/home/spuser/new_law/redebug_lawbrain/LawBrain/law_docs/æ··åˆæ¡ˆä¾‹'
            doc_type = 'hybrid_case'
        elif 'public' in knowledge_types:
            new_target_dir = '/home/spuser/new_law/redebug_lawbrain/LawBrain/law_docs/å…±æœ‰æ¡ˆä¾‹'
            doc_type = 'public_case'
        else:
            new_target_dir = f'/home/spuser/new_law/redebug_lawbrain/LawBrain/law_docs/ç§æœ‰æ¡ˆä¾‹/{data.user_id}'
            doc_type = 'private_case'
        
        # ç”Ÿæˆæ–°çš„æ–‡ä»¶è·¯å¾„
        safe_filename = sanitize_filename(current_title) + '.md'
        new_file_path = os.path.join(new_target_dir, safe_filename)
        
        print(f"[DEBUG] æ™ºèƒ½æ›´æ–°: æ–°ç›®æ ‡ç›®å½•: {new_target_dir}")
        print(f"[DEBUG] æ™ºèƒ½æ›´æ–°: æ–°æ–‡ä»¶è·¯å¾„: {new_file_path}")
        
        # å¦‚æœè·¯å¾„å‘ç”Ÿå˜åŒ–ï¼Œç§»åŠ¨ç‰©ç†æ–‡ä»¶
        if current_file_path != new_file_path:
            print(f"[DEBUG] æ™ºèƒ½æ›´æ–°: è·¯å¾„å˜åŒ–ï¼Œéœ€è¦ç§»åŠ¨æ–‡ä»¶")
            print(f"[DEBUG] æ™ºèƒ½æ›´æ–°: ä» {current_file_path} ç§»åŠ¨åˆ° {new_file_path}")
            
            # ç¡®ä¿æ–°ç›®æ ‡ç›®å½•å­˜åœ¨
            os.makedirs(new_target_dir, exist_ok=True)
            
            # ç§»åŠ¨æ–‡ä»¶
            if os.path.exists(current_file_path):
                os.rename(current_file_path, new_file_path)
                print(f"[DEBUG] æ™ºèƒ½æ›´æ–°: æ–‡ä»¶ç§»åŠ¨æˆåŠŸ")
            else:
                print(f"[WARNING] æ™ºèƒ½æ›´æ–°: åŸæ–‡ä»¶ä¸å­˜åœ¨: {current_file_path}")
            
            # æ›´æ–°æ•°æ®åº“ä¸­çš„æ–‡ä»¶è·¯å¾„
            pm.update_file_path(data.file_id, new_file_path)
            print(f"[DEBUG] æ™ºèƒ½æ›´æ–°: æ•°æ®åº“è·¯å¾„æ›´æ–°å®Œæˆ")
            
            # æ›´æ–°å‘é‡å­˜å‚¨ä¸­çš„å…ƒæ•°æ®
            import utils
            utils.update_vector_metadata(data.file_id, {'source': new_file_path})
            print(f"[DEBUG] æ™ºèƒ½æ›´æ–°: å‘é‡å…ƒæ•°æ®æ›´æ–°å®Œæˆ")
        else:
            print(f"[DEBUG] æ™ºèƒ½æ›´æ–°: è·¯å¾„æœªå˜åŒ–ï¼Œè·³è¿‡æ–‡ä»¶ç§»åŠ¨")
        
        # æ›´æ–°æ•°æ®åº“æƒé™ï¼ˆè¿™æ˜¯æ ¸å¿ƒæ“ä½œï¼‰
        print(f"[DEBUG] æ™ºèƒ½æ›´æ–°: æ›´æ–°æ•°æ®åº“æƒé™")
        success = permission_manager.add_file_with_permissions(
            file_id=data.file_id,
            user_id=data.user_id,
            title=current_title,
            file_path=new_file_path,
            knowledge_types=knowledge_types,
            file_category=data.file_category
        )
        
        if success:
            print(f"[DEBUG] æ™ºèƒ½æ›´æ–°: æƒé™æ›´æ–°æˆåŠŸ - æ–‡ä»¶ID: {data.file_id}, æƒé™: {knowledge_types}")
            logger.info(f"æ™ºèƒ½æ›´æ–°å®Œæˆ: æ–‡ä»¶ID {data.file_id}, æ–°æƒé™: {knowledge_types}")
            
            # å‘é€æˆåŠŸé€šçŸ¥
            await send_upload_success_notification(data)
            print(f"âœ… æ™ºèƒ½æ›´æ–°æˆåŠŸï¼æ–‡ä»¶ID: {data.file_id}, æ–‡ä»¶å: {data.filename}")
        else:
            print(f"[ERROR] æ™ºèƒ½æ›´æ–°: æƒé™æ›´æ–°å¤±è´¥ - æ–‡ä»¶ID: {data.file_id}")
            raise Exception("æ™ºèƒ½æ›´æ–°å¤±è´¥ï¼šæƒé™æ›´æ–°å¤±è´¥")
            
    except Exception as e:
        print(f"[ERROR] æ™ºèƒ½æ›´æ–°å¤±è´¥ {data.file_id}: {str(e)}")
        print(f"[ERROR] å¼‚å¸¸è¯¦æƒ…: {type(e).__name__}: {str(e)}")
        logger.error(f"æ™ºèƒ½æ›´æ–°å¤±è´¥ {data.file_id}: {str(e)}")
        
        # å‘é€å¤±è´¥é€šçŸ¥
        await send_upload_failure_notification(data, str(e))
        raise

async def process_new_knowledge(data: KnowledgeUploadData):
    """åå°å¤„ç†æ–°çŸ¥è¯†æ–‡ä»¶çš„å®Œæ•´æµç¨‹ - æ™ºèƒ½æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§"""
    temp_path = None
    try:
        print(f"[DEBUG] æ­¥éª¤0: å¼€å§‹å¤„ç†çŸ¥è¯†æ–‡ä»¶: {data.file_id}")
        logger.info(f"å¼€å§‹å¤„ç†çŸ¥è¯†æ–‡ä»¶: {data.file_id}")
        
        # ã€æ–°å¢ã€‘æ­¥éª¤0.5ï¼šæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        pm = permission_manager.get_permission_manager()
        existing_file_info = pm.get_file_info(data.file_id)
        
        if existing_file_info:
            print(f"[INFO] æ–‡ä»¶ {data.file_id} å·²å­˜åœ¨ï¼Œæ‰§è¡Œæ™ºèƒ½æ›´æ–°æ“ä½œ")
            return await handle_existing_file_update(data, existing_file_info, pm)
        
        print(f"[INFO] æ–‡ä»¶ {data.file_id} ä¸å­˜åœ¨ï¼Œæ‰§è¡Œå®Œæ•´æ–°å¢æµç¨‹")
        
        # æ­¥éª¤1ï¼šä¸‹è½½å¹¶æå–æ–‡æœ¬
        print(f"[DEBUG] æ­¥éª¤1: å¼€å§‹ä¸‹è½½æ–‡ä»¶: {data.file_path}")
        download_result = await download_file_from_minio(data.file_path)
        print(f"[DEBUG] æ­¥éª¤1: ä¸‹è½½ç»“æœ: {download_result}")
        if not download_result.get("success"):
            print(f"[ERROR] æ­¥éª¤1: æ–‡ä»¶ä¸‹è½½å¤±è´¥: {download_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            raise Exception(f"æ–‡ä»¶ä¸‹è½½å¤±è´¥: {download_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        temp_path = download_result.get("local_path")
        print(f"[DEBUG] æ­¥éª¤1: ä¸´æ—¶æ–‡ä»¶è·¯å¾„: {temp_path}")
        if not temp_path or not os.path.exists(temp_path):
            print(f"[ERROR] æ­¥éª¤1: æœ¬åœ°è·¯å¾„æ— æ•ˆæˆ–æ–‡ä»¶ä¸å­˜åœ¨: {temp_path}")
            raise Exception("æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼šæœ¬åœ°è·¯å¾„æ— æ•ˆ")
        
        print(f"[DEBUG] æ­¥éª¤1: å¼€å§‹æå–æ–‡æœ¬å†…å®¹")
        raw_text = extract_text_from_file(temp_path)
        print(f"[DEBUG] æ­¥éª¤1: æå–çš„æ–‡æœ¬é•¿åº¦: {len(raw_text) if raw_text else 0}")
        if not raw_text.strip():
            print(f"[ERROR] æ­¥éª¤1: æ–‡æœ¬æå–å¤±è´¥æˆ–æ–‡ä»¶ä¸ºç©º")
            raise Exception("æ–‡æœ¬æå–å¤±è´¥æˆ–æ–‡ä»¶ä¸ºç©º")
        
        # æ­¥éª¤2ï¼šè°ƒç”¨LLMè¿›è¡Œå†…å®¹ç»“æ„åŒ–
        print(f"[DEBUG] æ­¥éª¤2: å¼€å§‹LLMç»“æ„åŒ–å¤„ç†")
        structured_data = structure_content_with_llm(raw_text)
        print(f"[DEBUG] æ­¥éª¤2: LLMç»“æ„åŒ–å®Œæˆï¼Œæ ‡é¢˜: {structured_data.get('æ ‡é¢˜', 'N/A')}")
        
        # æ­¥éª¤3ï¼šç¡®å®šå…ƒæ•°æ®å’Œå­˜æ¡£è·¯å¾„
        print(f"[DEBUG] æ­¥éª¤3: ç¡®å®šå…ƒæ•°æ®å’Œå­˜æ¡£è·¯å¾„")
        knowledge_types = data.knowledge_types if data.knowledge_types else ['private']
        print(f"[DEBUG] æ­¥éª¤3: çŸ¥è¯†åº“ç±»å‹åˆ—è¡¨: {knowledge_types}")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ··åˆæ¨¡å¼ï¼ˆåŒæ—¶åŒ…å«publicå’Œprivateï¼‰
        is_hybrid = 'public' in knowledge_types and 'private' in knowledge_types
        
        if is_hybrid:
            # æ··åˆæ¨¡å¼ï¼šowner_idä¸ºåˆ—è¡¨ï¼ŒåŒ…å«systemå’Œç”¨æˆ·ID
            owner_id = ['system', str(data.user_id)]
            doc_type = 'hybrid_case'
            target_dir = '/home/spuser/new_law/redebug_lawbrain/LawBrain/law_docs/æ··åˆæ¡ˆä¾‹'
            print(f"[DEBUG] æ­¥éª¤3: æ··åˆæ¨¡å¼ - owner_id: {owner_id}")
        elif 'public' in knowledge_types:
            # çº¯å…¬å¼€æ¨¡å¼
            owner_id = ['system']
            doc_type = 'public_case'
            target_dir = '/home/spuser/new_law/redebug_lawbrain/LawBrain/law_docs/å…±æœ‰æ¡ˆä¾‹'
        else:
            # çº¯ç§æœ‰æ¨¡å¼
            owner_id = [str(data.user_id)]
            doc_type = 'private_case'
            target_dir = f'/home/spuser/new_law/redebug_lawbrain/LawBrain/law_docs/ç§æœ‰æ¡ˆä¾‹/{data.user_id}'
        
        print(f"[DEBUG] æ­¥éª¤3: ç›®æ ‡ç›®å½•: {target_dir}, æ–‡æ¡£ç±»å‹: {doc_type}, owner_id: {owner_id}")
        
        # åˆ›å»ºç®€åŒ–çš„å…ƒæ•°æ®ç»“æ„
        metadata_for_db = {
            'file_id': data.file_id,
            'title': structured_data.get('æ ‡é¢˜', 'untitled') or "æœªçŸ¥æ ‡é¢˜"
        }
        
        # æ­¥éª¤4ï¼šåºåˆ—åŒ–ä¸ºMarkdownå¹¶ç‰©ç†å­˜æ¡£
        print(f"[DEBUG] æ­¥éª¤4: å¼€å§‹åºåˆ—åŒ–ä¸ºMarkdownå¹¶ç‰©ç†å­˜æ¡£")
        title = structured_data.get('æ ‡é¢˜', 'untitled')
        safe_filename = sanitize_filename(title) + '.md'
        print(f"[DEBUG] æ­¥éª¤4: æ–‡ä»¶æ ‡é¢˜: {title}, å®‰å…¨æ–‡ä»¶å: {safe_filename}")
        
        # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
        print(f"[DEBUG] æ­¥éª¤4: åˆ›å»ºç›®æ ‡ç›®å½•: {target_dir}")
        os.makedirs(target_dir, exist_ok=True)
        
        final_save_path = os.path.join(target_dir, safe_filename)
        print(f"[DEBUG] æ­¥éª¤4: æœ€ç»ˆä¿å­˜è·¯å¾„: {final_save_path}")
        
        # æ›´æ–°å…ƒæ•°æ®ä¸­çš„sourceå­—æ®µ
        metadata_for_db['source'] = final_save_path
        
        # æ ¼å¼åŒ–ä¸ºMarkdownå¹¶ä¿å­˜
        print(f"[DEBUG] æ­¥éª¤4: æ ¼å¼åŒ–ä¸ºMarkdown")
        md_content = format_ideal_case_to_markdown(structured_data)
        print(f"[DEBUG] æ­¥éª¤4: Markdownå†…å®¹é•¿åº¦: {len(md_content)}")
        with open(final_save_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        print(f"[DEBUG] æ­¥éª¤4: æ–‡ä»¶ä¿å­˜å®Œæˆ")
        
        logger.info(f"æ–‡ä»¶å·²ä¿å­˜åˆ°: {final_save_path}")
        
        # æ­¥éª¤5ï¼šå‘é‡åŒ–å…¥åº“
        print(f"[DEBUG] æ­¥éª¤5: å¼€å§‹å‘é‡åŒ–å…¥åº“")
        print(f"[DEBUG] æ­¥éª¤5: å…ƒæ•°æ®: {metadata_for_db}")
        add_single_file_to_vectorstore(final_save_path, metadata_for_db, vectorstore_type='case')
        print(f"[DEBUG] æ­¥éª¤5: å‘é‡åŒ–å…¥åº“å®Œæˆ")
        
        # æ­¥éª¤6ï¼šæ³¨å†Œæ–‡ä»¶å’Œæƒé™åˆ°æ•°æ®åº“
        print(f"[DEBUG] æ­¥éª¤6: æ³¨å†Œæ–‡ä»¶å’Œæƒé™åˆ°æ•°æ®åº“")
        
        # ä½¿ç”¨permission_manageræ¨¡å—æ·»åŠ æ–‡ä»¶å’Œæƒé™
        success = permission_manager.add_file_with_permissions(
            file_id=data.file_id,
            user_id=data.user_id,
            title=title,
            file_path=final_save_path,
            knowledge_types=knowledge_types,
            file_category=data.file_category
        )
        
        if success:
            print(f"[DEBUG] æ­¥éª¤6: æ–‡ä»¶å’Œæƒé™æ³¨å†ŒæˆåŠŸ - æ–‡ä»¶ID: {data.file_id}, æƒé™: {knowledge_types}")
        else:
            print(f"[ERROR] æ­¥éª¤6: æ–‡ä»¶å’Œæƒé™æ³¨å†Œå¤±è´¥ - æ–‡ä»¶ID: {data.file_id}")
            raise Exception("æ–‡ä»¶å’Œæƒé™æ³¨å†Œå¤±è´¥")
        
        print(f"[DEBUG] æ‰€æœ‰æ­¥éª¤å®Œæˆ: çŸ¥è¯†æ–‡ä»¶å¤„ç†å®Œæˆ: {data.file_id}")
        print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼æ–‡ä»¶ID: {data.file_id}, æ–‡ä»¶å: {data.filename}")
        logger.info(f"çŸ¥è¯†æ–‡ä»¶å¤„ç†å®Œæˆ: {data.file_id}")
        logger.info(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼æ–‡ä»¶ID: {data.file_id}, æ–‡ä»¶å: {data.filename}")
        
        # å‘é€æˆåŠŸé€šçŸ¥
        await send_upload_success_notification(data)
        
    except Exception as e:
        print(f"[ERROR] å¤„ç†çŸ¥è¯†æ–‡ä»¶å¤±è´¥ {data.file_id}: {str(e)}")
        print(f"[ERROR] å¼‚å¸¸è¯¦æƒ…: {type(e).__name__}: {str(e)}")
        logger.error(f"å¤„ç†çŸ¥è¯†æ–‡ä»¶å¤±è´¥ {data.file_id}: {str(e)}")
        
        # å‘é€å¤±è´¥é€šçŸ¥
        await send_upload_failure_notification(data, str(e))
        raise
    finally:
        # æ­¥éª¤7ï¼šæ¸…ç†ä¸´æ—¶æ–‡ä»¶
        print(f"[DEBUG] æ­¥éª¤7: å¼€å§‹æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_path}")
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
                logger.info(f"ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†: {temp_path}")
            except Exception as e:
                logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")

async def send_upload_success_notification(data: KnowledgeUploadData):
    """å‘é€æ–‡ä»¶ä¸Šä¼ æˆåŠŸé€šçŸ¥"""
    try:
        # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦å®ç°ä¸åŒçš„é€šçŸ¥æ–¹å¼
        # ä¾‹å¦‚ï¼šå‘é€åˆ°æ¶ˆæ¯é˜Ÿåˆ—ã€è°ƒç”¨å›è°ƒAPIã€å‘é€é‚®ä»¶ç­‰
        
        success_message = {
            "event": "upload_success",
            "user_id": data.user_id,
            "file_id": data.file_id,
            "filename": data.filename,
            "message": f"æ–‡ä»¶ '{data.filename}' ä¸Šä¼ æˆåŠŸï¼",
            "timestamp": datetime.now().isoformat()
        }
        
        # æ‰“å°æˆåŠŸé€šçŸ¥ï¼ˆå¯ä»¥æ›¿æ¢ä¸ºå®é™…çš„é€šçŸ¥æœºåˆ¶ï¼‰
        print(f"ğŸ“¢ ä¸Šä¼ æˆåŠŸé€šçŸ¥: {success_message}")
        logger.info(f"ä¸Šä¼ æˆåŠŸé€šçŸ¥: {success_message}")
        
        # TODO: è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„é€šçŸ¥å‘é€é€»è¾‘
        # ä¾‹å¦‚ï¼š
        # - å‘é€åˆ°WebSocketè¿æ¥
        # - è°ƒç”¨å‰ç«¯å›è°ƒAPI
        # - å‘é€åˆ°æ¶ˆæ¯é˜Ÿåˆ—
        # - å‘é€é‚®ä»¶é€šçŸ¥
        
    except Exception as e:
        print(f"[ERROR] å‘é€ä¸Šä¼ æˆåŠŸé€šçŸ¥å¤±è´¥: {str(e)}")
        logger.error(f"å‘é€ä¸Šä¼ æˆåŠŸé€šçŸ¥å¤±è´¥: {str(e)}")

async def send_upload_failure_notification(data: KnowledgeUploadData, error_message: str):
    """å‘é€æ–‡ä»¶ä¸Šä¼ å¤±è´¥é€šçŸ¥"""
    try:
        failure_message = {
            "event": "upload_failure",
            "user_id": data.user_id,
            "file_id": data.file_id,
            "filename": data.filename,
            "message": f"æ–‡ä»¶ '{data.filename}' ä¸Šä¼ å¤±è´¥ï¼",
            "error": error_message,
            "timestamp": datetime.now().isoformat()
        }
        
        # æ‰“å°å¤±è´¥é€šçŸ¥
        print(f"âŒ ä¸Šä¼ å¤±è´¥é€šçŸ¥: {failure_message}")
        logger.error(f"ä¸Šä¼ å¤±è´¥é€šçŸ¥: {failure_message}")
        
        # TODO: è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„é€šçŸ¥å‘é€é€»è¾‘
        # ä¾‹å¦‚ï¼š
        # - å‘é€åˆ°WebSocketè¿æ¥
        # - è°ƒç”¨å‰ç«¯å›è°ƒAPI
        # - å‘é€åˆ°æ¶ˆæ¯é˜Ÿåˆ—
        # - å‘é€é‚®ä»¶é€šçŸ¥
        
    except Exception as e:
        print(f"[ERROR] å‘é€ä¸Šä¼ å¤±è´¥é€šçŸ¥å¤±è´¥: {str(e)}")
        logger.error(f"å‘é€ä¸Šä¼ å¤±è´¥é€šçŸ¥å¤±è´¥: {str(e)}")

async def new_intelligent_cancel(data: KnowledgeUploadData):
    """
    ã€å…¨æ–°æ™ºèƒ½åˆ é™¤å‡½æ•°ã€‘æ­£ç¡®ä½¿ç”¨permission_manageræ¨¡å—å¤„ç†æ™ºèƒ½åˆ é™¤è¯·æ±‚
    """
    file_id = data.file_id
    user_id = data.user_id
    permissions_to_remove = set(data.knowledge_types or [])

    print(f"[æ™ºèƒ½åˆ é™¤] å¼€å§‹å¤„ç†æ–‡ä»¶ {file_id}ã€‚è¯·æ±‚ç§»é™¤æƒé™: {permissions_to_remove}")

    try:
        # 1. è·å–ç®¡ç†å™¨
        pm = permission_manager.get_permission_manager()
        
        # 2. æŸ¥è¯¢ç°çŠ¶
        file_info = pm.get_file_info(file_id)
        if not file_info:
            msg = f"æ–‡ä»¶ {file_id} ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤ï¼Œå–æ¶ˆæ“ä½œæˆåŠŸã€‚"
            print(f"[INFO] {msg}")
            await send_upload_success_notification(data)
            return {"status": "success", "message": msg}

        current_path = file_info['file_path']
        current_permissions_info = pm.get_file_permissions(file_id)
        current_permission_types = {p['permission_type'] for p in current_permissions_info}
        print(f"[æ™ºèƒ½åˆ é™¤] æ–‡ä»¶å½“å‰æƒé™: {current_permission_types}")

        # 3. è®¡ç®—å‰©ä½™æƒé™
        remaining_permissions = current_permission_types - permissions_to_remove
        print(f"[æ™ºèƒ½åˆ é™¤] è®¡ç®—åå‰©ä½™æƒé™: {remaining_permissions}")

        # 4. åˆ¤æ–­å¹¶æ‰§è¡Œ
        if not remaining_permissions:
            # --- åˆ†æ”¯Aï¼šæ‰§è¡Œå®Œå…¨åˆ é™¤ ---
            print(f"[æ™ºèƒ½åˆ é™¤] å†³ç­–ï¼šå®Œå…¨åˆ é™¤æ–‡ä»¶ {file_id}")
            
            # a. åˆ é™¤ç‰©ç†æ–‡ä»¶
            if os.path.exists(current_path):
                os.remove(current_path)
                print(f"ç‰©ç†æ–‡ä»¶å·²åˆ é™¤: {current_path}")
            
            # b. åˆ é™¤æ•°æ®åº“è®°å½• (æƒé™è®°å½•ä¼šçº§è”åˆ é™¤)
            pm.delete_file(file_id)
            print(f"æ•°æ®åº“è®°å½•å·²åˆ é™¤: file_id={file_id}")
            
            # c. åˆ é™¤å‘é‡ç´¢å¼•
            vectorstore = get_case_vectorstore()
            vectorstore.delete(where={'file_id': file_id})
            print(f"å‘é‡æ•°æ®åº“ç´¢å¼•å·²åˆ é™¤: file_id={file_id}")
            
            await send_upload_success_notification(data)
            return {"status": "success", "message": "æ–‡ä»¶å·²å®Œå…¨åˆ é™¤"}

        else:
            # --- åˆ†æ”¯Bï¼šæ‰§è¡Œéƒ¨åˆ†åˆ é™¤ï¼ˆæƒé™æ›´æ–°ï¼‰ ---
            print(f"[æ™ºèƒ½åˆ é™¤] å†³ç­–ï¼šæ›´æ–°æ–‡ä»¶ {file_id} çš„æƒé™ä¸º {remaining_permissions}")
            
            # a. æ›´æ–°æ•°æ®åº“ä¸­çš„æƒé™
            pm.set_file_permissions(file_id, list(remaining_permissions), user_id)
            print("æ•°æ®åº“æƒé™è®°å½•å·²æ›´æ–°ã€‚")

            # b. åˆ¤æ–­æ˜¯å¦éœ€è¦ç§»åŠ¨æ–‡ä»¶å¹¶æ‰§è¡Œ
            if 'public' in remaining_permissions:
                new_target_dir = '/home/spuser/new_law/redebug_lawbrain/LawBrain/law_docs/å…±æœ‰æ¡ˆä¾‹'
            else:  # private only
                new_target_dir = f'/home/spuser/new_law/redebug_lawbrain/LawBrain/law_docs/ç§æœ‰æ¡ˆä¾‹/{user_id}'

            new_path = os.path.join(new_target_dir, os.path.basename(current_path))

            if current_path != new_path:
                print(f"æ–‡ä»¶ä½ç½®å˜æ›´ï¼Œç§»åŠ¨: {current_path} -> {new_path}")
                os.makedirs(os.path.dirname(new_path), exist_ok=True)
                os.rename(current_path, new_path)
                
                # c. æ›´æ–°æ•°æ®åº“ä¸­çš„æ–‡ä»¶è·¯å¾„
                pm.update_file_path(file_id, new_path)
                print("æ•°æ®åº“æ–‡ä»¶è·¯å¾„å·²æ›´æ–°ã€‚")
                
                # d. æ›´æ–°å‘é‡åº“ä¸­çš„sourceå…ƒæ•°æ®
                from utils import update_vector_metadata
                update_vector_metadata(file_id, {'source': new_path})
                print("å‘é‡æ•°æ®åº“sourceå…ƒæ•°æ®å·²æ›´æ–°ã€‚")
            
            await send_upload_success_notification(data)
            return {"status": "success", "message": "æƒé™å·²æ›´æ–°", "remaining_permissions": list(remaining_permissions)}
            
    except Exception as e:
        print(f"[ERROR] æ™ºèƒ½åˆ é™¤æ“ä½œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        await send_upload_failure_notification(data, f"æ“ä½œå¤±è´¥: {e}")
        return {
            "status": "error",
            "message": f"å–æ¶ˆå¤„ç†å¤±è´¥: {str(e)}",
            "file_id": data.file_id,
            "user_id": data.user_id
        }


# process_full_deletionå‡½æ•°å·²è¢«åˆ é™¤ï¼ŒåŠŸèƒ½å·²æ•´åˆåˆ°new_intelligent_cancelä¸­

# process_permission_updateå‡½æ•°å·²è¢«åˆ é™¤ï¼ŒåŠŸèƒ½å·²æ•´åˆåˆ°new_intelligent_cancelä¸­

# process_knowledge_removalå‡½æ•°å·²è¢«åˆ é™¤ï¼ŒåŠŸèƒ½å·²æ•´åˆåˆ°new_intelligent_cancelä¸­

# åˆå§‹åŒ–æ•°æ®åº“
init_database()

class CompleteQASystem:
    """
    å®Œæ•´é—®ç­”ç³»ç»Ÿç±» - é›†æˆcomplete_qa_test.pyçš„æ‰€æœ‰åŠŸèƒ½
    """
    
    def __init__(self):
        """åˆå§‹åŒ–é—®ç­”ç³»ç»Ÿ"""
        self.vectorstore = get_vectorstore(config.LAW_VS_COLLECTION_NAME)
        self.law_vectorstore = get_law_vectorstore()
        self.case_vectorstore = get_case_vectorstore()
        self.model = get_model_openai()
        self.memory = get_memory()
        
        # åˆå§‹åŒ–BM25ç´¢å¼•
        self.bm25_index = self._create_bm25_index()
    
    def _create_bm25_index(self) -> BM25Okapi:
        """åˆ›å»ºBM25ç´¢å¼•"""
        try:
            # è·å–æ‰€æœ‰æ–‡æ¡£
            all_docs = self.vectorstore.similarity_search("", k=1000)
            
            # é¢„å¤„ç†æ–‡æ¡£æ–‡æœ¬
            tokenized_docs = []
            for doc in all_docs:
                text = doc.page_content.replace('\t', ' ').replace('\n', ' ')
                tokens = list(text.replace(' ', ''))
                tokens = [token for token in tokens if token.strip()]
                if tokens:
                    tokenized_docs.append(tokens)
            
            return BM25Okapi(tokenized_docs)
        except Exception as e:
            print(f"BM25ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
            return None
    
    def step1_question_completion(self, question: str, chat_history: str = "") -> str:
        """æ­¥éª¤1: é—®é¢˜è¡¥å…¨"""
        try:
            input_data = {
                "question": question,
                "chat_history": chat_history
            }
            
            chain = PRE_QUESTION_PROMPT | self.model | StrOutputParser()
            completed_question = chain.invoke(input_data)
            return completed_question
        except Exception as e:
            print(f"é—®é¢˜è¡¥å…¨å¤±è´¥: {e}")
            return question
    
    def step2_intent_recognition(self, question: str) -> str:
        """æ­¥éª¤2: æ„å›¾è¯†åˆ«"""
        try:
            chain = CHECK_INTENT_PROMPT | self.model | StrOutputParser()
            intent = chain.invoke({"question": question}).strip().lower()
            return intent
        except Exception as e:
            print(f"æ„å›¾è¯†åˆ«å¤±è´¥: {e}")
            return "other"
    
    def step3_multi_query_generation(self, question: str) -> List[str]:
        """æ­¥éª¤3: ç”Ÿæˆå¤šæŸ¥è¯¢"""
        try:
            chain = MULTI_QUERY_PROMPT_TEMPLATE | self.model | StrOutputParser()
            multi_queries_text = chain.invoke({"question": question})
            
            queries = [line.strip() for line in multi_queries_text.strip().split("\n") if line.strip()]
            return queries
        except Exception as e:
            print(f"å¤šæŸ¥è¯¢ç”Ÿæˆå¤±è´¥: {e}")
            return [question]
    
    def step4_knowledge_retrieval(self, multi_queries: List[str], mode: str, user_id: str = None, top_k: int = 10) -> List[Document]:
        """ã€é‡æ„ç‰ˆæœ¬ã€‘æ­¥éª¤4: çŸ¥è¯†åº“æ£€ç´¢ - ç²¾ç¡®çš„æ¨¡å¼åŒ–æ£€ç´¢ç­–ç•¥
        
        æ ¹æ®ä¸åŒçš„çŸ¥è¯†åº“æ¨¡å¼é‡‡ç”¨ç²¾ç¡®çš„æ£€ç´¢ç­–ç•¥ï¼š
        - public_knowledge: åªæŸ¥å…¬å…±çŸ¥è¯†ï¼ˆå…¬å…±æ³•å¾‹+å…¬å…±æ¡ˆä¾‹ï¼‰
        - private_knowledge: åªæŸ¥è¯¥ç”¨æˆ·çš„ç§æœ‰çŸ¥è¯†ï¼ˆå…¬å…±æ³•å¾‹+ç§æœ‰æ¡ˆä¾‹ï¼‰
        - entire_knowledge: æŸ¥ç”¨æˆ·å¯è®¿é—®çš„å…¨éƒ¨çŸ¥è¯†ï¼ˆå…¬å…±æ³•å¾‹+å…¬å…±æ¡ˆä¾‹+ç§æœ‰æ¡ˆä¾‹ï¼‰
        - none_knowledge: ä¸ä½¿ç”¨çŸ¥è¯†åº“
        
        å…¼å®¹æ—§çš„modeåç§°ï¼š
        - shared_knowledge -> public_knowledge
        """
        try:
            # æ¨¡å¼åç§°å…¼å®¹æ€§è½¬æ¢
            if mode == "shared_knowledge":
                mode = "public_knowledge"
                print(f"ğŸ”„ æ¨¡å¼è½¬æ¢: shared_knowledge -> public_knowledge")
            
            if mode == "none_knowledge":
                print("è·³è¿‡çŸ¥è¯†åº“æ£€ç´¢ - modeä¸ºnone_knowledge")
                return []

            main_query = multi_queries[0] if multi_queries else ""
            if not main_query:
                print("è­¦å‘Šï¼šæ²¡æœ‰æœ‰æ•ˆçš„æŸ¥è¯¢è¯­å¥ï¼Œè·³è¿‡æ£€ç´¢ã€‚")
                return []

            print(f"ğŸ¯ å¼€å§‹ç²¾ç¡®æ£€ç´¢ (æ¨¡å¼: {mode})ï¼Œç›®æ ‡æ•°é‡: æ³•å¾‹æ¡æ–‡{top_k}ç¯‡ + æ¡ˆä¾‹{top_k}ç¯‡")
            
            # 1. æ³•å¾‹æ¡æ–‡æ£€ç´¢ï¼šæ‰€æœ‰æ¨¡å¼éƒ½æ£€ç´¢å…¬å…±æ³•å¾‹æ¡æ–‡
            print(f"ğŸ“š å¼€å§‹æ£€ç´¢æ³•å¾‹æ¡æ–‡ï¼Œç›®æ ‡æ•°é‡: {top_k}")
            law_docs = search_law_documents(
                question=main_query,
                k=top_k,
                use_rerank=True,
                rerank_top_k=top_k
            )
            print(f"âœ… æ£€ç´¢åˆ° {len(law_docs)} ç¯‡ç›¸å…³æ³•å¾‹æ¡æ–‡")

            # 2. æ¡ˆä¾‹æ–‡æ¡£æ£€ç´¢ï¼šæ ¹æ®æ¨¡å¼æ‰§è¡Œä¸åŒçš„æ£€ç´¢ç­–ç•¥
            case_docs = []
            
            if mode == "public_knowledge":
                print(f"ğŸŒ å…¬å…±çŸ¥è¯†æ¨¡å¼ï¼šæ£€ç´¢å…¬å…±æ¡ˆä¾‹ï¼Œç›®æ ‡æ•°é‡: {top_k}")
                # è·å–å…¬å…±æ–‡ä»¶IDåˆ—è¡¨
                public_file_ids = get_public_files()
                if public_file_ids:
                    case_docs = self._search_case_documents_by_file_ids(
                        question=main_query, 
                        file_ids=public_file_ids, 
                        k=top_k
                    )
                else:
                    print("âš ï¸ æœªæ‰¾åˆ°å…¬å…±æ¡ˆä¾‹æ–‡ä»¶")
                    
            elif mode == "private_knowledge":
                if user_id:
                    try:
                        user_id_int = int(user_id)
                        print(f"ğŸ”’ ç§æœ‰çŸ¥è¯†æ¨¡å¼ï¼šæ£€ç´¢ç”¨æˆ·{user_id_int}çš„ç§æœ‰æ¡ˆä¾‹ï¼Œç›®æ ‡æ•°é‡: {top_k}")
                        # è·å–ç”¨æˆ·ç§æœ‰æ–‡ä»¶IDåˆ—è¡¨
                        private_file_ids = get_user_private_files(user_id_int)
                        if private_file_ids:
                            case_docs = self._search_case_documents_by_file_ids(
                                question=main_query, 
                                file_ids=private_file_ids, 
                                k=top_k
                            )
                            print(f"âœ… æ£€ç´¢åˆ° {len(case_docs)} ç¯‡ç§æœ‰æ¡ˆä¾‹")
                        else:
                            print(f"âš ï¸ ç”¨æˆ·{user_id_int}æ²¡æœ‰ç§æœ‰æ¡ˆä¾‹æ–‡ä»¶")
                            case_docs = []
                    except (ValueError, TypeError) as e:
                        print(f"âŒ ç”¨æˆ·IDè½¬æ¢å¤±è´¥: {user_id}, é”™è¯¯: {e}")
                        case_docs = []
                else:
                    print("âš ï¸ ç§æœ‰çŸ¥è¯†åº“æ¨¡å¼ä½†æœªæä¾›user_id")
                    case_docs = []
                
                # private_knowledgeæ¨¡å¼ï¼šåªè¿”å›ç§æœ‰æ¡ˆä¾‹ï¼Œä¸åŒ…å«æ³•å¾‹æ¡æ–‡
                print(f"ğŸ‰ ç§æœ‰çŸ¥è¯†æ£€ç´¢å®Œæˆï¼Œè¿”å› {len(case_docs)} ç¯‡ç§æœ‰æ¡ˆä¾‹")
                return case_docs
                    
            elif mode == "entire_knowledge":
                if user_id:
                    try:
                        user_id_int = int(user_id)
                        print(f"ğŸŒ å…¨é‡çŸ¥è¯†æ¨¡å¼ï¼šæ£€ç´¢å…¬å…±+ç”¨æˆ·{user_id_int}ç§æœ‰æ¡ˆä¾‹ï¼Œç›®æ ‡æ•°é‡: {top_k * 3} -> é‡æ’åºä¿ç•™{top_k}")
                        
                        # è·å–å…¬å…±æ–‡ä»¶å’Œç”¨æˆ·ç§æœ‰æ–‡ä»¶ID
                        public_file_ids = get_public_files()
                        private_file_ids = get_user_private_files(user_id_int)
                        all_accessible_file_ids = list(set(public_file_ids + private_file_ids))
                        
                        if all_accessible_file_ids:
                            # æ£€ç´¢æ›´å¤šæ–‡æ¡£ç„¶åé‡æ’åº
                            case_docs = self._search_case_documents_by_file_ids(
                                question=main_query, 
                                file_ids=all_accessible_file_ids, 
                                k=top_k * 3  # æ£€ç´¢3å€æ•°é‡
                            )
                            # é‡æ’åºä¿ç•™top_kä¸ª
                            if len(case_docs) > top_k:
                                case_docs = rerank_existing_documents(
                                    question=main_query,
                                    docs=case_docs,
                                    top_k=top_k
                                )
                        else:
                            print(f"âš ï¸ ç”¨æˆ·{user_id_int}æ²¡æœ‰å¯è®¿é—®çš„æ¡ˆä¾‹æ–‡ä»¶")
                    except (ValueError, TypeError) as e:
                        print(f"âŒ ç”¨æˆ·IDè½¬æ¢å¤±è´¥: {user_id}, é”™è¯¯: {e}")
                        # Fallback: åªæ£€ç´¢å…¬å…±æ¡ˆä¾‹
                        public_file_ids = get_public_files()
                        if public_file_ids:
                            case_docs = self._search_case_documents_by_file_ids(
                                question=main_query, 
                                file_ids=public_file_ids, 
                                k=top_k
                            )
                else:
                    print("âš ï¸ å…¨é‡çŸ¥è¯†åº“æ¨¡å¼ä½†æœªæä¾›user_idï¼Œå›é€€åˆ°å…¬å…±çŸ¥è¯†æ¨¡å¼")
                    # Fallback: åªæ£€ç´¢å…¬å…±æ¡ˆä¾‹
                    public_file_ids = get_public_files()
                    if public_file_ids:
                        case_docs = self._search_case_documents_by_file_ids(
                            question=main_query, 
                            file_ids=public_file_ids, 
                            k=top_k
                        )
            else:
                print(f"âŒ æœªçŸ¥çš„æ£€ç´¢æ¨¡å¼: {mode}ï¼Œå›é€€åˆ°å…¬å…±çŸ¥è¯†æ¨¡å¼")
                # Fallback: å…¬å…±çŸ¥è¯†æ¨¡å¼
                public_file_ids = get_public_files()
                if public_file_ids:
                    case_docs = self._search_case_documents_by_file_ids(
                        question=main_query, 
                        file_ids=public_file_ids, 
                        k=top_k
                    )
                
            print(f"âœ… æ£€ç´¢åˆ° {len(case_docs)} ç¯‡ç›¸å…³æ¡ˆä¾‹")

            # 3. åˆå¹¶æ³•å¾‹æ¡æ–‡å’Œæ¡ˆä¾‹æ–‡æ¡£
            final_docs = law_docs + case_docs
            print(f"ğŸ‰ æ£€ç´¢æµç¨‹å®Œæˆï¼Œæ€»è®¡è¿”å› {len(final_docs)} ç¯‡æ–‡æ¡£ (æ³•å¾‹æ¡æ–‡: {len(law_docs)}, æ¡ˆä¾‹: {len(case_docs)})")
            return final_docs
                
        except Exception as e:
            print(f"âŒ çŸ¥è¯†åº“æ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _search_case_documents_by_file_ids(self, question: str, file_ids: List[int], k: int) -> List[Document]:
        """æ ¹æ®æ–‡ä»¶IDåˆ—è¡¨æ£€ç´¢æ¡ˆä¾‹æ–‡æ¡£çš„å†…éƒ¨è¾…åŠ©å‡½æ•°"""
        try:
            if not file_ids:
                return []
            
            # ä½¿ç”¨ç°æœ‰çš„search_case_documentså‡½æ•°ï¼Œä½†æ·»åŠ æ–‡ä»¶IDè¿‡æ»¤
            # è¿™é‡Œæˆ‘ä»¬éœ€è¦ä¿®æ”¹utilsä¸­çš„å‡½æ•°æˆ–è€…ç›´æ¥åœ¨è¿™é‡Œå®ç°è¿‡æ»¤é€»è¾‘
            # æš‚æ—¶ä½¿ç”¨ç°æœ‰å‡½æ•°ï¼Œåç»­å¯ä»¥ä¼˜åŒ–
            case_docs = search_case_documents(
                question=question, 
                k=k * 2,  # æ£€ç´¢æ›´å¤šç„¶åè¿‡æ»¤
                use_rerank=True, 
                rerank_top_k=k
            )
            
            # è¿‡æ»¤å‡ºæŒ‡å®šæ–‡ä»¶IDçš„æ–‡æ¡£
            filtered_docs = []
            for doc in case_docs:
                doc_file_id = doc.metadata.get('file_id')
                if doc_file_id and int(doc_file_id) in file_ids:
                    filtered_docs.append(doc)
                if len(filtered_docs) >= k:
                    break
            
            return filtered_docs[:k]
            
        except Exception as e:
            print(f"âŒ æ ¹æ®æ–‡ä»¶IDæ£€ç´¢æ¡ˆä¾‹æ–‡æ¡£å¤±è´¥: {e}")
            return []
    
    def step5_separated_reranking(self, law_docs: List, case_docs: List, question: str, top_k: int = 10) -> Dict:
        """æ­¥éª¤5: åˆ†ç¦»å¼é‡æ’åº - æ–°é€»è¾‘ï¼šå¯¹kç¯‡æ³•å¾‹æ¡æ–‡å’Œkç¯‡æ¡ˆä¾‹åˆ†åˆ«è¿›è¡Œé‡æ’åº"""
        try:
            # æ–°é€»è¾‘ï¼šç›´æ¥ä½¿ç”¨kå€¼è¿›è¡Œé‡æ’åºï¼Œä¸å†è¿›è¡Œå¤æ‚çš„åˆ†é…è®¡ç®—
            # å¯¹æ³•å¾‹æ¡æ–‡é‡æ’åºä¿ç•™kç¯‡ï¼Œå¯¹æ¡ˆä¾‹æ–‡æ¡£é‡æ’åºä¿ç•™kç¯‡
            law_rerank_k = top_k  # æ³•å¾‹æ¡æ–‡é‡æ’åºä¿ç•™kç¯‡
            case_rerank_k = top_k  # æ¡ˆä¾‹æ–‡æ¡£é‡æ’åºä¿ç•™kç¯‡
            
            reranked_law_docs = []
            reranked_case_docs = []
            
            # å¯¹æ³•å¾‹æ¡æ–‡è¿›è¡Œé‡æ’åº
            if law_docs:
                print(f"å¯¹{len(law_docs)}ç¯‡æ³•å¾‹æ¡æ–‡è¿›è¡Œé‡æ’åºï¼Œä¿ç•™å‰{law_rerank_k}ç¯‡")
                from utils import rerank_existing_documents
                reranked_law_docs = rerank_existing_documents(
                    question=question,
                    docs=law_docs,
                    top_k=law_rerank_k
                )
            
            # å¯¹æ¡ˆä¾‹è¿›è¡Œé‡æ’åº
            if case_docs:
                print(f"å¯¹{len(case_docs)}ç¯‡æ¡ˆä¾‹è¿›è¡Œé‡æ’åºï¼Œä¿ç•™å‰{case_rerank_k}ç¯‡")
                from utils import rerank_existing_documents
                reranked_case_docs = rerank_existing_documents(
                    question=question,
                    docs=case_docs,
                    top_k=case_rerank_k
                )
            
            print(f"é‡æ’åºç»“æœ: {len(reranked_law_docs)}ç¯‡æ³•å¾‹æ¡æ–‡ + {len(reranked_case_docs)}ç¯‡æ¡ˆä¾‹æ–‡æ¡£ = æ€»è®¡{len(reranked_law_docs) + len(reranked_case_docs)}ç¯‡")
            
            return {
                'reranked_law_docs': reranked_law_docs,
                'reranked_case_docs': reranked_case_docs,
                'total_count': len(reranked_law_docs) + len(reranked_case_docs)
            }
            
        except Exception as e:
            print(f"é‡æ’åºå¤±è´¥: {e}")
            return {
                'reranked_law_docs': law_docs,  # å¤±è´¥æ—¶è¿”å›åŸå§‹æ–‡æ¡£
                'reranked_case_docs': case_docs,
                'total_count': len(law_docs) + len(case_docs)
            }
    
    def step6_web_search(self, question: str, num_results: int = 3) -> str:
        """æ­¥éª¤6: è”ç½‘æ£€ç´¢"""
        try:
            web_content = search_web_serper(question, num_results)
            return web_content if web_content else ""
        except Exception as e:
            print(f"è”ç½‘æ£€ç´¢å¤±è´¥: {e}")
            return ""
    
    def _extract_urls_from_web_content(self, web_content: str) -> List[str]:
        """ä»ç½‘ç»œæœç´¢å†…å®¹ä¸­æå–ç½‘å€"""
        import re
        urls = []
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…"æ¥æº: "åé¢çš„ç½‘å€
        url_pattern = r'æ¥æº: (https?://[^\s]+)'
        matches = re.findall(url_pattern, web_content)
        
        for url in matches:
            urls.append(url)
        
        return urls
    
    def _create_source_summary(self, context_docs: List[Document]) -> str:
        """ä½¿ç”¨LLMæ ¹æ®ä¸Šä¸‹æ–‡æ–‡æ¡£ç”Ÿæˆæ¥æºæ‘˜è¦"""
        if not context_docs:
            return ""

        # 1. å°†æ–‡æ¡£åˆ†ç¦»ä¸ºæ³•å¾‹å’Œæ¡ˆä¾‹
        law_docs = [doc for doc in context_docs if doc.metadata.get('doc_type') == 'law']
        case_docs = [doc for doc in context_docs if doc.metadata.get('doc_type') == 'case']

        print(f"ğŸ“Š è°ƒè¯•è¾“å‡º - æ–‡æ¡£åˆ†ç±»ç»Ÿè®¡:")
        print(f"  æ³•å¾‹æ¡æ–‡æ–‡æ¡£æ•°é‡: {len(law_docs)}")
        print(f"  æ¡ˆä¾‹æ–‡æ¡£æ•°é‡: {len(case_docs)}")
        
        # 2. å‡†å¤‡Promptçš„è¾“å…¥å†…å®¹
        # æ”¹è¿›æ³•å¾‹æ¡æ–‡æ ¼å¼ï¼Œæä¾›æ›´å¤šå…ƒæ•°æ®ä¿¡æ¯
        law_context_parts = []
        for doc in law_docs:
            source = doc.metadata.get('source', 'æœªçŸ¥æ¥æº')
            title = doc.metadata.get('title', '')
            content = doc.page_content
            
            # å°è¯•ä»titleæˆ–contentä¸­æå–æ¡æ–‡å·ä¿¡æ¯
            if title and 'ç¬¬' in title and 'æ¡' in title:
                law_context_parts.append(f"ã€Š{source}ã€‹{title}: {content}")
            else:
                law_context_parts.append(f"ã€Š{source}ã€‹: {content}")
        
        law_context_str = "\n".join(law_context_parts)
        # å¯¹äºæ¡ˆä¾‹ï¼Œæˆ‘ä»¬åªæå–æ ‡é¢˜ï¼ˆé€šå¸¸åœ¨å…ƒæ•°æ®é‡Œï¼‰ï¼Œè®©LLMå»æ€»ç»“
        case_context_str = "\n".join([f"ã€Š{doc.metadata.get('title', 'æœªçŸ¥æ¡ˆä¾‹')}ã€‹å…¨æ–‡ï¼š{doc.page_content}" for doc in case_docs])

        # å¦‚æœæ²¡æœ‰å¯¹åº”ç±»å‹çš„æ–‡æ¡£ï¼Œåˆ™ä¼ å…¥æç¤ºä¿¡æ¯
        if not law_context_str:
            law_context_str = "æ— "
        if not case_context_str:
            case_context_str = "æ— "
            
        print(f"ğŸ“ è°ƒè¯•è¾“å‡º - æ³•å¾‹æ¡æ–‡æ‘˜è¦éƒ¨åˆ†:")
        if law_docs:
            for i, doc in enumerate(law_docs, 1):
                source = doc.metadata.get('source', 'æœªçŸ¥æ¥æº')
                content_preview = doc.page_content[:100] + "..." if len(doc.page_content) > 100 else doc.page_content
                print(f"  {i}. ã€Š{source}ã€‹: {content_preview}")
        else:
            print(f"  æ— æ³•å¾‹æ¡æ–‡æ–‡æ¡£")
            
        print(f"ğŸ“ è°ƒè¯•è¾“å‡º - æ¡ˆä¾‹æ‘˜è¦éƒ¨åˆ†:")
        if case_docs:
            for i, doc in enumerate(case_docs, 1):
                title = doc.metadata.get('title', 'æœªçŸ¥æ¡ˆä¾‹')
                content_preview = doc.page_content[:100] + "..." if len(doc.page_content) > 100 else doc.page_content
                print(f"  {i}. ã€Š{title}ã€‹: {content_preview}")
        else:
            print(f"  æ— æ¡ˆä¾‹æ–‡æ¡£")
            
        # 3. æ„å»ºå¹¶è°ƒç”¨æ‘˜è¦ç”Ÿæˆé“¾
        try:
            from prompt import SOURCE_SUMMARY_PROMPT
            from langchain_core.output_parsers import StrOutputParser

            summary_chain = SOURCE_SUMMARY_PROMPT | self.model | StrOutputParser()
            
            summary = summary_chain.invoke({
                "law_context": law_context_str,
                "case_context": case_context_str
            })
            
            print(f"ğŸ¯ è°ƒè¯•è¾“å‡º - ç”Ÿæˆçš„å®Œæ•´æ‘˜è¦:")
            print(f"{summary.strip()}")
            
            return summary.strip()
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ¥æºæ‘˜è¦å¤±è´¥: {e}")
            return ""  # å‡ºé”™æ—¶è¿”å›ç©ºå­—ç¬¦ä¸²

    def step7_final_answer_generation(self, question: str, intent: str, context_docs: List = None, web_content: str = "", chat_history: List = None) -> Dict[str, str]:
        """æ­¥éª¤7: æœ€ç»ˆå›ç­”ç”Ÿæˆ - ç°åœ¨è¿”å›ä¸€ä¸ªåŒ…å«ä¸»å›ç­”å’Œæ¥æºæ‘˜è¦çš„å­—å…¸ã€‚"""
        final_answer = ""
        source_summary = ""

        try:
            if intent == "law":
                # ä½¿ç”¨æ³•å¾‹é—®ç­”é“¾
                from chain import get_law_chain
                from callback import OutCallbackHandler
                out_callback = OutCallbackHandler()
                law_chain = get_law_chain(config, out_callback)
                
                # å‡†å¤‡ä¸Šä¸‹æ–‡
                context = ""
                if context_docs:
                    context = "\n\n".join([doc.page_content for doc in context_docs])
                
                if web_content:
                    context += "\n\nç½‘ç»œæœç´¢ç»“æœ:\n" + web_content
                
                # å‡†å¤‡è¾“å…¥
                chain_input = {
                    "question": question,
                    "context": context
                }
                
                # å¦‚æœæœ‰å¯¹è¯å†å²ï¼Œæ·»åŠ åˆ°è¾“å…¥ä¸­
                if chat_history:
                    chain_input["chat_history"] = chat_history
                
                response = law_chain.invoke(chain_input)
                
                # ä»å“åº”ä¸­æå–answerå­—æ®µ
                if isinstance(response, dict) and 'answer' in response:
                    final_answer = response['answer']
                else:
                    final_answer = str(response)

                # --- ã€æ–°å¢ã€‘ç”Ÿæˆæ¥æºæ‘˜è¦çš„é€»è¾‘ ---
                if context_docs:
                    print("\nâœï¸ å¼€å§‹ç”Ÿæˆæ¥æºæ‘˜è¦...")
                    source_summary = self._create_source_summary(context_docs)
                    print(f"æ¥æºæ‘˜è¦ç”Ÿæˆå®Œæ¯•:\n{source_summary}")
                    
                    # --- ã€æ–°å¢ã€‘æ·»åŠ ç½‘ç»œæœç´¢æ¥æºç½‘å€ ---
                    if web_content:
                        web_urls = self._extract_urls_from_web_content(web_content)
                        if web_urls:
                            source_summary += "\n\n**ç½‘ç»œæœç´¢æ¥æºï¼š**\n" + "\n".join(web_urls)

            else:
                # éæ³•å¾‹é—®é¢˜çš„å‹å¥½æ‹’ç»
                from prompt import FRIENDLY_REJECTION_PROMPT
                model = get_model()
                response = model.invoke(FRIENDLY_REJECTION_PROMPT.format(question=question))
                final_answer = response.content if hasattr(response, 'content') else str(response)
                
        except Exception as e:
            print(f"å›ç­”ç”Ÿæˆå¤±è´¥: {e}")
            final_answer = "æŠ±æ­‰ï¼Œç³»ç»Ÿæš‚æ—¶æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
        
        # --- è¿”å›åŒ…å«ä¸¤éƒ¨åˆ†çš„å­—å…¸ ---
        return {
            "main_answer": final_answer,
            "source_summary": source_summary
        }
    
    def complete_qa_process(self, question: str, user_id: str = None, chat_history: List = None, 
                           top_k: int = 10, web_search: bool = False, mode = "shared_knowledge") -> Dict[str, Any]:
        """å®Œæ•´é—®ç­”æµç¨‹ - æ ¹æ®ç”¨æˆ·æè¿°çš„æ ¸å¿ƒå¤„ç†æµç¨‹å®ç°"""
        results = {
            "original_question": question,
            "user_id": user_id,
            "mode": mode
        }
        
        print(f"ğŸš€ å¼€å§‹å®Œæ•´é—®ç­”æµç¨‹")
        print(f"åŸå§‹é—®é¢˜: {question}")
        print(f"ç”¨æˆ·ID: {user_id}")
        print(f"æ£€ç´¢æ¨¡å¼: {mode}")
        print(f"æ£€ç´¢æ•°é‡: {top_k}")
        print(f"è”ç½‘æœç´¢: {web_search}")
        
        # ç¬¬äºŒæ­¥ï¼šè·å–å¹¶å¤„ç†å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå·²åœ¨è°ƒç”¨å‰å¤„ç†ï¼‰
        # è½¬æ¢chat_historyä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œåªä¿ç•™ç”¨æˆ·æ¶ˆæ¯ç”¨äºé—®é¢˜è¡¥å…¨
        chat_history_str = ""
        if chat_history:
            # åªä¿ç•™ç”¨æˆ·çš„æ¶ˆæ¯ï¼Œè¿‡æ»¤æ‰åŠ©æ‰‹çš„å›ç­”ï¼Œé¿å…å°†åŠ©æ‰‹å›ç­”å½“ä½œé—®é¢˜è¡¥å…¨çš„è¾“å…¥
            user_messages = []
            for msg in chat_history:
                role = msg.get('role', 'user')
                content = msg.get('content', '')
                if role == 'user' and content.strip():
                    user_messages.append(f"ç”¨æˆ·: {content}")
            
            chat_history_str = "\n".join(user_messages)
            print(f"å¯¹è¯ä¸Šä¸‹æ–‡é•¿åº¦: {len(chat_history)} æ¡æ¶ˆæ¯ï¼Œç”¨æˆ·æ¶ˆæ¯: {len(user_messages)} æ¡")
            print(f"ç”¨äºé—®é¢˜è¡¥å…¨çš„å†å²: {chat_history_str[:200]}..." if len(chat_history_str) > 200 else f"ç”¨äºé—®é¢˜è¡¥å…¨çš„å†å²: {chat_history_str}")
        
        # ç¬¬ä¸‰æ­¥ï¼šé—®é¢˜é¢„å¤„ç†ä¸æ„å›¾è¯†åˆ«
        print("\nğŸ“ ç¬¬ä¸‰æ­¥ï¼šé—®é¢˜é¢„å¤„ç†ä¸æ„å›¾è¯†åˆ«")
        
        # æ­¥éª¤1: é—®é¢˜è¡¥å…¨
        print("æ‰§è¡Œé—®é¢˜è¡¥å…¨...")
        completed_question = self.step1_question_completion(question, chat_history_str)
        results["completed_question"] = completed_question
        print(f"è¡¥å…¨åé—®é¢˜: {completed_question}")
        
        # æ­¥éª¤2: æ„å›¾è¯†åˆ«
        print("æ‰§è¡Œæ„å›¾è¯†åˆ«...")
        intent = self.step2_intent_recognition(completed_question)
        results["intent"] = intent
        print(f"è¯†åˆ«æ„å›¾: {intent}")
        
        # ç¬¬å››æ­¥ï¼šæ ¹æ®æ„å›¾æ‰§è¡Œä¸åŒé€»è¾‘åˆ†æ”¯
        print(f"\nğŸ”€ ç¬¬å››æ­¥ï¼šæ ¹æ®æ„å›¾æ‰§è¡Œä¸åŒé€»è¾‘åˆ†æ”¯")
        
        if intent == "law":
            print("âœ… æ„å›¾ä¸ºæ³•å¾‹é—®é¢˜ï¼Œæ‰§è¡Œå®Œæ•´æ³•å¾‹é—®ç­”æµç¨‹")
            
            # æ­¥éª¤3: å¤šæŸ¥è¯¢ç”Ÿæˆ
            print("\nğŸ” ç”Ÿæˆå¤šæŸ¥è¯¢...")
            multi_queries = self.step3_multi_query_generation(completed_question)
            results["multi_queries"] = multi_queries
            print(f"ç”ŸæˆæŸ¥è¯¢æ•°é‡: {len(multi_queries)}")
            for i, query in enumerate(multi_queries, 1):
                print(f"  æŸ¥è¯¢{i}: {query}")
            
            # ã€å…¨æ–°ã€ç®€åŒ–çš„æ­¥éª¤4ã€‘
            print(f"\nğŸ“š æ‰§è¡ŒçŸ¥è¯†åº“æ£€ç´¢ä¸æ’åº (æ¨¡å¼: {mode})...")
            # ç›´æ¥è°ƒç”¨æ–°çš„step4ï¼Œå®ƒä¼šå®Œæˆæ‰€æœ‰æ£€ç´¢å’Œæ’åºï¼Œå¹¶è¿”å›æœ€ç»ˆçš„æ–‡æ¡£åˆ—è¡¨
            reranked_docs = self.step4_knowledge_retrieval(
                multi_queries, mode, user_id, top_k
            )
            results["retrieved_docs_count"] = len(reranked_docs)  # æ›´æ–°æ—¥å¿—key
            print(f"æœ€ç»ˆç”¨äºç”Ÿæˆå›ç­”çš„æ–‡æ¡£æ•°é‡: {len(reranked_docs)}")
            
            # ã€å½»åº•åˆ é™¤æ­¥éª¤5ã€‘
            # self.step5_separated_reranking(...) æ•´ä¸ªæ­¥éª¤å’Œç›¸å…³çš„kå€¼è®¡ç®—éƒ½åˆ æ‰
            
            # æ­¥éª¤6: è”ç½‘æ£€ç´¢
            web_content = ""
            if web_search:
                print("\nğŸŒ æ‰§è¡Œè”ç½‘æœç´¢...")
                web_content = self.step6_web_search(completed_question)
                print(f"ç½‘ç»œæœç´¢å†…å®¹é•¿åº¦: {len(web_content)}")
            else:
                print("\nâŒ è·³è¿‡è”ç½‘æœç´¢")
            results["web_content_length"] = len(web_content)
            
            # æ­¥éª¤7: æœ€ç»ˆå›ç­”ç”Ÿæˆ
            print("\nğŸ’¬ ç”Ÿæˆæœ€ç»ˆå›ç­”...")
            # ã€æ–°è°ƒç”¨æ–¹å¼ã€‘æ¥æ”¶ä¸€ä¸ªå­—å…¸
            final_result_dict = self.step7_final_answer_generation(
                completed_question, intent, reranked_docs, web_content, chat_history
            )
            
            # ã€æ–°ç»„è£…é€»è¾‘ã€‘æ‹¼æ¥ä¸»å›ç­”å’Œæ¥æºæ‘˜è¦
            main_answer = final_result_dict.get("main_answer", "")
            source_summary = final_result_dict.get("source_summary", "")
            
            final_answer_with_summary = main_answer
            # å¦‚æœæ¥æºæ‘˜è¦ä¸ä¸ºç©ºï¼Œåˆ™æ·»åŠ 
            if source_summary:
                final_answer_with_summary += f"\n\n{source_summary}"
            
            # å°†æ‹¼æ¥åçš„å®Œæ•´ç»“æœå­˜å…¥ results
            results["final_answer"] = final_answer_with_summary
            print(f"æœ€ç»ˆå®Œæ•´å›ç­”é•¿åº¦: {len(final_answer_with_summary)}")
            
        else:
            print("â„¹ï¸ æ„å›¾ä¸ºéæ³•å¾‹é—®é¢˜ï¼Œæ‰§è¡Œç®€åŒ–æµç¨‹")
            
            # åˆ†æ”¯Aï¼šæ„å›¾ä¸º"other"(éæ³•å¾‹é—®é¢˜)
            results["multi_queries"] = []
            results["retrieved_docs_count"] = 0
            results["reranked_docs_count"] = 0
            
            # æ£€æŸ¥æ˜¯å¦è”ç½‘
            web_content = ""
            if web_search:
                print("\nğŸŒ æ‰§è¡Œè”ç½‘æœç´¢...")
                web_content = self.step6_web_search(completed_question)
                print(f"ç½‘ç»œæœç´¢å†…å®¹é•¿åº¦: {len(web_content)}")
            else:
                print("\nâŒ è·³è¿‡è”ç½‘æœç´¢")
            results["web_content_length"] = len(web_content)
            
            # ç”Ÿæˆæœ€ç»ˆå›ç­”
            print("\nğŸ’¬ ç”Ÿæˆå‹å¥½å›ç­”...")
            # ã€æ–°è°ƒç”¨æ–¹å¼ã€‘æ¥æ”¶ä¸€ä¸ªå­—å…¸
            final_result_dict = self.step7_final_answer_generation(
                completed_question, intent, [], web_content, chat_history
            )
            
            # ã€æ–°ç»„è£…é€»è¾‘ã€‘æ‹¼æ¥ä¸»å›ç­”å’Œæ¥æºæ‘˜è¦
            main_answer = final_result_dict.get("main_answer", "")
            source_summary = final_result_dict.get("source_summary", "")
            
            final_answer_with_summary = main_answer
            # å¦‚æœæ¥æºæ‘˜è¦ä¸ä¸ºç©ºï¼Œåˆ™æ·»åŠ 
            if source_summary:
                final_answer_with_summary += f"\n\n{source_summary}"
            
            # å°†æ‹¼æ¥åçš„å®Œæ•´ç»“æœå­˜å…¥ results
            results["final_answer"] = final_answer_with_summary
            print(f"æœ€ç»ˆå®Œæ•´å›ç­”é•¿åº¦: {len(final_answer_with_summary)}")
        
        print("\nâœ… å®Œæ•´é—®ç­”æµç¨‹ç»“æŸ")
        return results

# å…¨å±€é—®ç­”ç³»ç»Ÿå®ä¾‹
qa_system = CompleteQASystem()

async def download_file_from_minio(file_path: str, save_path: str = None, user_id: int = None, category: str = None) -> dict:
    """ä»MinIOæœåŠ¡ä¸‹è½½æ–‡ä»¶åˆ°æŒ‡å®šè·¯å¾„
    
    Args:
        file_path: MinIOæ–‡ä»¶è·¯å¾„
        save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰
        user_id: ç”¨æˆ·IDï¼ˆç”¨äºç”Ÿæˆè·¯å¾„ï¼‰
        category: æ–‡ä»¶åˆ†ç±»ï¼ˆç”¨äºç”Ÿæˆè·¯å¾„ï¼‰
    
    Returns:
        dict: åŒ…å«ä¸‹è½½ç»“æœçš„å­—å…¸
    """
    try:
        print(f"[DEBUG] MinIOä¸‹è½½: å¼€å§‹ä¸‹è½½æ–‡ä»¶: {file_path}")
        async with aiohttp.ClientSession() as session:
            payload = {"minio_path": file_path}
            print(f"[DEBUG] MinIOä¸‹è½½: è¯·æ±‚è½½è·: {payload}")
            print(f"[DEBUG] MinIOä¸‹è½½: è¯·æ±‚URL: http://192.168.240.1:5000/api/file-download/download")
            async with session.post(
                "http://192.168.240.1:5000/api/file-download/download",
                json=payload,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                print(f"[DEBUG] MinIOä¸‹è½½: å“åº”çŠ¶æ€ç : {response.status}")
                if response.status == 200:
                    print(f"[DEBUG] MinIOä¸‹è½½: å¼€å§‹è¯»å–æ–‡ä»¶å†…å®¹")
                    # è·å–æ–‡ä»¶å†…å®¹
                    file_content = await response.read()
                    print(f"[DEBUG] MinIOä¸‹è½½: æ–‡ä»¶å†…å®¹å¤§å°: {len(file_content)} bytes")
                    
                    # è·å–æ–‡ä»¶å
                    filename = None
                    content_disposition = response.headers.get('Content-Disposition', '')
                    print(f"[DEBUG] MinIOä¸‹è½½: Content-Disposition: {content_disposition}")
                    if 'filename=' in content_disposition:
                        filename = content_disposition.split('filename=')[1].strip('"')
                    else:
                        filename = os.path.basename(file_path)
                    print(f"[DEBUG] MinIOä¸‹è½½: è§£æçš„æ–‡ä»¶å: {filename}")
                    
                    # ç¡®å®šä¿å­˜è·¯å¾„
                    if save_path is None:
                        save_path = generate_save_path(filename, user_id, category)
                    print(f"[DEBUG] MinIOä¸‹è½½: ä¿å­˜è·¯å¾„: {save_path}")
                    
                    # ç¡®ä¿ç›®å½•å­˜åœ¨
                    save_dir = os.path.dirname(save_path)
                    print(f"[DEBUG] MinIOä¸‹è½½: åˆ›å»ºç›®å½•: {save_dir}")
                    Path(save_dir).mkdir(parents=True, exist_ok=True)
                    
                    # ä¿å­˜æ–‡ä»¶åˆ°æŒ‡å®šè·¯å¾„
                    print(f"[DEBUG] MinIOä¸‹è½½: å¼€å§‹å†™å…¥æ–‡ä»¶")
                    async with aiofiles.open(save_path, 'wb') as f:
                        await f.write(file_content)
                    print(f"[DEBUG] MinIOä¸‹è½½: æ–‡ä»¶å†™å…¥å®Œæˆ")
                    
                    logger.info(f"æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {save_path}")
                    
                    return {
                        "success": True,
                        "local_path": save_path,
                        "filename": filename,
                        "size": len(file_content),
                        "content_type": response.headers.get('Content-Type')
                    }
                else:
                    error_text = await response.text()
                    error_msg = f"æ–‡ä»¶ä¸‹è½½å¤±è´¥: HTTP {response.status}"
                    print(f"[DEBUG] MinIOä¸‹è½½: ä¸‹è½½å¤±è´¥ - çŠ¶æ€ç : {response.status}")
                    print(f"[DEBUG] MinIOä¸‹è½½: é”™è¯¯å“åº”å†…å®¹: {error_text}")
                    logger.error(error_msg)
                    return {
                        "success": False,
                        "error": error_msg
                    }
    except Exception as e:
        error_msg = f"MinIOæ–‡ä»¶ä¸‹è½½å¼‚å¸¸: {str(e)}"
        print(f"[DEBUG] MinIOä¸‹è½½: å‘ç”Ÿå¼‚å¸¸: {error_msg}")
        logger.error(error_msg)
        return {
            "success": False,
            "error": error_msg
        }

def generate_save_path(filename: str, user_id: int = None, category: str = None) -> str:
    """aiå†™çš„ç”Ÿæˆä¿å­˜è·¯å¾„çš„è„šæœ¬"""
    import uuid
    from datetime import datetime
    
    # åŸºç¡€ä¸‹è½½ç›®å½•
    base_dir = "/tmp/downloads"  # å¯ä»¥é€šè¿‡é…ç½®æ–‡ä»¶è®¾ç½®
    
    # æ ¹æ®ç”¨æˆ·IDå’Œåˆ†ç±»åˆ›å»ºå­ç›®å½•
    if user_id and category:
        sub_dir = os.path.join(base_dir, category, str(user_id))
    elif user_id:
        sub_dir = os.path.join(base_dir, "users", str(user_id))
    elif category:
        sub_dir = os.path.join(base_dir, category)
    else:
        sub_dir = os.path.join(base_dir, "general")
    
    # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åï¼ˆé¿å…é‡åï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    unique_id = str(uuid.uuid4())[:8]
    name, ext = os.path.splitext(filename)
    unique_filename = f"{name}_{timestamp}_{unique_id}{ext}"
    
    return os.path.join(sub_dir, unique_filename)


class ChatPara(BaseModel):
    user_id:int
    username:str
    embedding_model:str
    large_language_model:str
    top_k:int
    web_search:str
    mode:str
    question:str
    conversation_id:int
    recent_messages_count: int = 3 # è¿™ä¸ªé»˜è®¤æ˜¯3ï¼Œ
@app.post("/api/chat")
async def chat(data:ChatPara):
    '''
    ç”¨ä¾‹ï¼š
    æ¥æ”¶åˆ°ç”¨æˆ·èŠå¤©è¯·æ±‚
    ç”¨æˆ·ID: 3
    ç”¨æˆ·å: chen
    åµŒå…¥æ¨¡å‹: text2vec-base
    å¤§æ¨¡å‹: ChatGLM-6B
    topk: 20
    æ˜¯å¦è”ç½‘æœç´¢: notUse
    æ˜¯å¦ä½¿ç”¨çŸ¥è¯†åº“ï¼ˆæ¨¡å¼ï¼‰: knowledgeQA
    é—®é¢˜: ä½ å¥½å•Š
    å¯¹è¯idï¼š23
    æå–æœ€è¿‘ 6 æ¡æ¶ˆæ¯ä½œä¸ºä¸Šä¸‹æ–‡
    [{'content': 'ï¼Ÿ', 'role': 'user'}, {'content': 'æ­£åœ¨æ€è€ƒä¸­...', 'role': 'assistant'}, {'content': 'æ€ä¹ˆæ ·å‘¢', 'role': 'user'}, {'content': 'æ­£åœ¨æ€è€ƒä¸­...', 'role': 'assistant'}, {'content': 'å‚»é€¼', 'role': 'user'}, {'content': 'æ­£åœ¨æ€è€ƒä¸­...', 'role': 'assistant'}]
    æˆåŠŸè·å–å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œæ¶ˆæ¯æ•°é‡: 29
    '''
    try:
        print(f"æ¥æ”¶åˆ°ç”¨æˆ·èŠå¤©è¯·æ±‚")
        print(f"ç”¨æˆ·ID: {data.user_id}")
        print(f"ç”¨æˆ·å: {data.username}")
        print(f"åµŒå…¥æ¨¡å‹: {data.embedding_model}")
        print(f"å¤§æ¨¡å‹: {data.large_language_model}")
        print(f"topk: {data.top_k}")
        print(f"æ˜¯å¦è”ç½‘æœç´¢: {data.web_search}")
        print(f"æ˜¯å¦ä½¿ç”¨çŸ¥è¯†åº“ï¼ˆæ¨¡å¼ï¼‰: {data.mode}")
        print(f"é—®é¢˜: {data.question}")
        print(f"å¯¹è¯idï¼š{data.conversation_id}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        
    conversation_context = None
    if data.conversation_id:
        try:
                # ä»æœ¬æœºè·å–å¯¹è¯ä¸Šä¸‹æ–‡
            local_api_base="http://192.168.240.1:5000"    
            context_url = f"{local_api_base}/api/conversations/{data.conversation_id}/context" 
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(context_url)
                    
            if response.status_code == 200:
                conversation_context = response.json()
                if 'messages' in conversation_context:
                        all_messages = conversation_context['messages']
                        recent_count = min(data.recent_messages_count * 2, len(all_messages))
                        recent_messages = all_messages[-recent_count:] if recent_count > 0 else []# è¿™ä¸ªæ˜¯æ•°æ®åº“æŸ¥å‡ºæ¥çš„ç›´æ¥ç»“æœï¼Œå¯èƒ½åŒ…å«å¾ˆå¤šæ²¡ç”¨çš„
                        simplified_messages = []# åªæœ‰roleå’Œcontent å»ºè®®ä½¿ç”¨è¿™ä¸ª
                        for msg in recent_messages:
                            simplified_messages.append({
                                'content': msg.get('content', ''),
                                'role': msg.get('role', '')
                            })        
                print(f"æå–æœ€è¿‘ {len(recent_messages)} æ¡æ¶ˆæ¯ä½œä¸ºä¸Šä¸‹æ–‡")
                print(simplified_messages)
                print(f"æˆåŠŸè·å–å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œæ¶ˆæ¯æ•°é‡: {conversation_context.get('message_count', 0)}")
            elif response.status_code == 404:
                print(f"å¯¹è¯ä¸å­˜åœ¨: {data.conversation_id}")
                conversation_context = None
            else:
                print(f"è·å–å¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                conversation_context = None
                    
        except httpx.TimeoutException:
            print(f"è·å–å¯¹è¯ä¸Šä¸‹æ–‡è¶…æ—¶: {data.conversation_id}")
            conversation_context = None
        except Exception as e:
            print(f"è·å–å¯¹è¯ä¸Šä¸‹æ–‡å¼‚å¸¸: {str(e)}")
            conversation_context = None
    # ä½¿ç”¨å®Œæ•´é—®ç­”ç³»ç»Ÿå¤„ç†è¯·æ±‚
    try:
        print(f"\n=== ç¬¬ä¸€æ­¥ï¼šæ¥æ”¶å¹¶è§£æç”¨æˆ·è¯·æ±‚ ===")
        print(f"ç”¨æˆ·ID: {data.user_id}")
        print(f"ç”¨æˆ·å: {data.username}")
        print(f"åµŒå…¥æ¨¡å‹: {data.embedding_model}")
        print(f"å¤§è¯­è¨€æ¨¡å‹: {data.large_language_model}")
        print(f"æ£€ç´¢æ•°é‡(top_k): {data.top_k}")
        print(f"è”ç½‘æœç´¢: {data.web_search}")
        print(f"çŸ¥è¯†åº“æ¨¡å¼: {data.mode}")
        print(f"é—®é¢˜: {data.question}")
        print(f"å¯¹è¯ID: {data.conversation_id}")
        
        # éªŒè¯modeå‚æ•°
        valid_modes = ["shared_knowledge", "private_knowledge", "entire_knowledge", "none_knowledge", "knowledgeQA"]
        if data.mode not in valid_modes:
            print(f"âŒ æ— æ•ˆçš„modeå‚æ•°: {data.mode}")
            return {
                "status": "error",
                "message": f"ä¸æ”¯æŒçš„æ¨¡å¼: {data.mode}ã€‚æ”¯æŒçš„æ¨¡å¼: {', '.join(valid_modes[:-1])}",
                "user_id": data.user_id,
                "conversation_id": data.conversation_id
            }
        
        # æ ¹æ®modeå‚æ•°å†³å®šå¤„ç†æ–¹å¼
        if data.mode in ["shared_knowledge", "private_knowledge", "entire_knowledge", "none_knowledge"]:
            print(f"\nğŸš€ æ‰§è¡ŒçŸ¥è¯†åº“é—®ç­”æ¨¡å¼: {data.mode}")
            
            # ä½¿ç”¨å®Œæ•´é—®ç­”ç³»ç»Ÿå¤„ç†
            qa_results = qa_system.complete_qa_process(
                question=data.question,
                user_id=str(data.user_id),  # ç¡®ä¿user_idä¸ºå­—ç¬¦ä¸²
                chat_history=simplified_messages if conversation_context else None,
                top_k=data.top_k,
                web_search=data.web_search.lower() == "use",
                mode=data.mode
            )
            
            print(f"\n=== å¤„ç†ç»“æœæ‘˜è¦ ===")
            print(f"åŸå§‹é—®é¢˜: {qa_results.get('original_question', '')}")
            print(f"è¡¥å…¨é—®é¢˜: {qa_results.get('completed_question', '')}")
            print(f"æ„å›¾è¯†åˆ«: {qa_results.get('intent', 'unknown')}")
            print(f"å¤šæŸ¥è¯¢æ•°é‡: {len(qa_results.get('multi_queries', []))}")
            print(f"æ£€ç´¢æ–‡æ¡£æ•°: {qa_results.get('retrieved_docs_count', 0)}")
            print(f"  - æ³•å¾‹æ¡æ–‡: {qa_results.get('law_docs_count', 0)} ä¸ª")
            print(f"  - æ¡ˆä¾‹æ–‡æ¡£: {qa_results.get('case_docs_count', 0)} ä¸ª")
            print(f"é‡æ’åºåæ–‡æ¡£æ•°: {qa_results.get('reranked_docs_count', 0)}")
            print(f"ç½‘ç»œæœç´¢å†…å®¹é•¿åº¦: {qa_results.get('web_content_length', 0)}")
            print(f"æœ€ç»ˆå›ç­”é•¿åº¦: {len(qa_results.get('final_answer', ''))}")
            
            return {
                "status": "success",
                "message": qa_results.get("final_answer", "å¤„ç†å®Œæˆ"),
                "user_id": data.user_id,
                "conversation_id": data.conversation_id
            }
        else:
            # å…¼å®¹æ—§çš„modeå‚æ•°æˆ–æœªçŸ¥mode
            if data.mode == "knowledgeQA":
                # å…¼å®¹æ—§ç‰ˆæœ¬ï¼Œé»˜è®¤ä½¿ç”¨shared_knowledgeæ¨¡å¼
                print(f"\nğŸ”„ å…¼å®¹æ¨¡å¼ï¼šå°†knowledgeQAè½¬æ¢ä¸ºshared_knowledgeæ¨¡å¼")
                qa_results = qa_system.complete_qa_process(
                    question=data.question,
                    user_id=str(data.user_id),
                    chat_history=simplified_messages if conversation_context else None,
                    top_k=data.top_k,
                    web_search=data.web_search.lower() == "use",
                    mode="shared_knowledge"
                )
                
                return {
                    "status": "success",
                    "message": qa_results.get("final_answer", "å¤„ç†å®Œæˆ"),
                    "user_id": data.user_id,
                    "conversation_id": data.conversation_id
                }
            else:
                # è¿™é‡Œä¸åº”è¯¥åˆ°è¾¾ï¼Œå› ä¸ºå·²ç»åœ¨å¼€å§‹éªŒè¯äº†modeå‚æ•°
                return {
                    "status": "error",
                    "message": f"å†…éƒ¨é”™è¯¯ï¼šæœªå¤„ç†çš„æ¨¡å¼ {data.mode}",
                    "user_id": data.user_id,
                    "conversation_id": data.conversation_id
                }
            
    except Exception as e:
        print(f"âŒ å®Œæ•´é—®ç­”æµç¨‹å¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            "status": "error",
            "message": f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
            "user_id": data.user_id,
            "conversation_id": data.conversation_id
        }


@app.post("/api/receive-knowledge")
async def receive_knowledge_upload(data: KnowledgeUploadData, background_tasks: BackgroundTasks):
    '''
    ç”¨ä¾‹ï¼š
    æ¥æ”¶åˆ°çŸ¥è¯†åº“ä¸Šä¼ æ•°æ®:
    ç”¨æˆ·ID: 4
    ç”¨æˆ·å: ghz
    æ–‡ä»¶è·¯å¾„: law-documents/cases/9df800525c1e46ab8fd47593e83c2885.pdf
    æ–‡ä»¶å: é™ˆç»§æ˜€_Facebook-Cambridgeæ•°æ®ä¸‘é—».pdf
    æ–‡ä»¶åˆ†ç±»: case
    çŸ¥è¯†åº“ç±»å‹: ['public', 'private']
    æ–‡ä»¶ID: 2
    æ‰§è¡ŒåŠ¨ä½œ: add
    '''
    try:
        # å¤„ç†æ¥æ”¶åˆ°çš„æ•°æ®
        print(f"æ¥æ”¶åˆ°çŸ¥è¯†åº“ä¸Šä¼ æ•°æ®:")
        print(f"ç”¨æˆ·ID: {data.user_id}")
        print(f"ç”¨æˆ·å: {data.username}")
        print(f"æ–‡ä»¶è·¯å¾„: law-documents/{data.file_path}")
        print(f"æ–‡ä»¶å: {data.filename}")
        print(f"æ–‡ä»¶åˆ†ç±»: {data.file_category}")
        print(f"çŸ¥è¯†åº“ç±»å‹: {str(data.knowledge_types)}")#å…¬æœ‰æˆ–è€…æ˜¯ç§æœ‰æ˜¯ä¸€ä¸ªåˆ—è¡¨['public'] ['private']æˆ–è€…æ˜¯['public','private']
        print(f"æ–‡ä»¶ID: {data.file_id}")
        print(f"æ‰§è¡ŒåŠ¨ä½œ: {data.action}")
        

        # æ•°æ®éªŒè¯
        if not data.file_path or not data.filename:
            print(f"âŒ æ•°æ®æ ¼å¼é”™è¯¯: æ–‡ä»¶è·¯å¾„æˆ–æ–‡ä»¶åä¸ºç©º")
            return JSONResponse(
                status_code=422,
                content={
                    "status": "error",
                    "message": "æ•°æ®æ ¼å¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥è¿œç¨‹æœåŠ¡å™¨é…ç½®",
                    "error_code": "INVALID_DATA",
                    "file_id": data.file_id,
                    "user_id": data.user_id
                }
            )

        data.file_path ="law-documents/"+data.file_path
        
        if data.action=="add":
            print("å¼€å§‹å¤„ç†æ–‡ä»¶ä¸Šä¼ ")
            try:
                # åŒæ­¥å¤„ç†ä¸Šä¼ æ“ä½œï¼Œä»¥ä¾¿èƒ½å¤Ÿè¿”å›å‡†ç¡®çš„æˆåŠŸ/å¤±è´¥çŠ¶æ€
                await process_new_knowledge(data)
                
                # è¿”å›æˆåŠŸå“åº” - HTTP 200
                print(f"æˆåŠŸå‘é€åˆ°è¿œç¨‹æœåŠ¡å™¨({data.file_id}): {{response.json()}}")
                return JSONResponse(
                    status_code=200,
                    content={
                        "status": "success",
                        "message": f"æ–‡ä»¶ '{data.filename}' ä¸Šä¼ æˆåŠŸï¼",
                        "file_id": data.file_id,
                        "user_id": data.user_id,
                        "timestamp": datetime.now().isoformat()
                    }
                )
            except Exception as e:
                # è¿”å›å¤±è´¥å“åº” - HTTP 500
                error_message = f"è¿œç¨‹æœåŠ¡å™¨è¿”å›é”™è¯¯: {str(e)}"
                print(f"âŒ å‘é€åˆ°è¿œç¨‹æœåŠ¡å™¨å¤±è´¥: {error_message}")
                logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥ {data.file_id}: {str(e)}")
                return JSONResponse(
                    status_code=500,
                    content={
                        "status": "error",
                        "message": error_message,
                        "error_code": "UPLOAD_FAILED",
                        "file_id": data.file_id,
                        "user_id": data.user_id,
                        "timestamp": datetime.now().isoformat()
                    }
                )
                        
        elif data.action=="cancel":
            print(f"[DEBUG] å¼€å§‹å¤„ç†cancelæ“ä½œ - ç”¨æˆ·ID: {data.user_id}, æ–‡ä»¶ID: {data.file_id}, æ–‡ä»¶å: {data.filename}")
            logger.info(f"å¼€å§‹å¤„ç†cancelæ“ä½œ - ç”¨æˆ·ID: {data.user_id}, æ–‡ä»¶ID: {data.file_id}, æ–‡ä»¶å: {data.filename}")
            
            try:
                result = await new_intelligent_cancel(data)
                
                # æ ¹æ®ç»“æœè¿”å›ç›¸åº”çš„çŠ¶æ€ç 
                if result["status"] == "success":
                    response_content = {
                        "status": "success",
                        "message": result["message"],
                        "file_id": data.file_id,
                        "user_id": data.user_id,
                        "timestamp": datetime.now().isoformat()
                    }
                    if "remaining_permissions" in result:
                        response_content["remaining_permissions"] = result["remaining_permissions"]
                    return JSONResponse(status_code=200, content=response_content)
                else:
                    return JSONResponse(status_code=500, content={
                        "status": "error",
                        "message": result["message"],
                        "error_code": "DELETE_FAILED",
                        "file_id": data.file_id,
                        "user_id": data.user_id,
                        "timestamp": datetime.now().isoformat()
                    })
            except Exception as e:
                print(f"[DEBUG] cancelæ“ä½œå¤±è´¥ - é”™è¯¯: {str(e)}")
                logger.error(f"cancelæ“ä½œå¤±è´¥ - é”™è¯¯: {str(e)}", exc_info=True)
                
                # è¿”å›åˆ é™¤å¤±è´¥å“åº” - HTTP 500
                return JSONResponse(
                    status_code=500,
                    content={
                        "status": "error",
                        "message": f"æ–‡ä»¶ '{data.filename}' åˆ é™¤å¤±è´¥: {str(e)}",
                        "error_code": "DELETE_FAILED",
                        "file_id": data.file_id,
                        "user_id": data.user_id,
                        "timestamp": datetime.now().isoformat()
                    }
                )
        else:
            # ä¸æ”¯æŒçš„æ“ä½œ - HTTP 422
            return JSONResponse(
                status_code=422,
                content={
                    "status": "error",
                    "message": f"ä¸æ”¯æŒçš„æ“ä½œ: {data.action}",
                    "error_code": "UNSUPPORTED_ACTION",
                    "file_id": data.file_id,
                    "user_id": data.user_id
                }
            )
            
    except Exception as e:
        logger.error(f"å¤„ç†çŸ¥è¯†åº“ä¸Šä¼ æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
        # è¿”å›æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ - HTTP 500
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}",
                "error_code": "INTERNAL_ERROR",
                "timestamp": datetime.now().isoformat()
            }
        )

@app.get("/health")
async def health_check():
    return {"status": "healthy"}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=10086)
